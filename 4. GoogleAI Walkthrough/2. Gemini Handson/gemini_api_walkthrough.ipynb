{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f5da68-31b4-4f66-8e3c-de6705eac5c9",
   "metadata": {},
   "source": [
    "# **Introduction to GoogleAI**\n",
    "\n",
    "Launched in December 2023 after PaLM and LaMDA.\n",
    "\n",
    "You can use Gemini chatbot which was formally known as Bard. Google announced Bard in February 2023 as a GenAI chatbot powered by LaMDA. Later chatbot switched to PaLM model before finally switching to the Gemini model. \n",
    "\n",
    "Let's list down a few reasons as why you might want to choose Gemini.\n",
    "- **Context Window:** In May 2024, Gemini 1.5 was updated with a context window of 2 million tokens. To put that in perspective, 2 million tokens can  process up to 2 hours of video, 22 hours of audio, 60K lines of code, or 1.4 million words of text.\n",
    "- **Multimodal Capabilities:** Works with text, images and videos.\n",
    "- **Variety of options:** Variants: Ultra, Pro, Flash and Nano.\n",
    "- **Generous free offerings:** Offers a free to use option.\n",
    "\n",
    "**Important Links:**\n",
    "1. [Gemini Chatbot](https://gemini.google.com/app)\n",
    "2. []()\n",
    "\n",
    "**Dependencies:**\n",
    "```python\n",
    "! pip install google-generativeai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51ed763-72b9-4f29-b10e-b75c537597c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d7b5d-b943-4bab-bbbe-8a176fd5130e",
   "metadata": {},
   "source": [
    "## **Importing Google Gemini AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb7d1b8-f430-4f9b-b2a4-417a8db6313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0b31b-e2db-43e7-9999-347e3c441724",
   "metadata": {},
   "source": [
    "## **Setting the API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad6eea9-585d-427f-aa76-da4d26111804",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/.gemini.txt\")\n",
    "key = f.read()\n",
    "\n",
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991360dd-a618-479a-904d-5e07661e2697",
   "metadata": {},
   "source": [
    "## **Available Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2122cd5-8425-435b-b5d8-17efcf5362fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef743af-5075-469a-9126-200e13439f7c",
   "metadata": {},
   "source": [
    "## **Prompting the Gemini Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ced0d0-98ef-48a5-bb03-8372a4576604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our solar system, Earth is a **planet**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "user_prompt = \"\"\"Complete the following:\n",
    "                In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0e6f5b-63c6-4d7d-a488-ed22c6344a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our solar system, Earth is a **rocky planet**, the **third planet from the Sun**, and the **only known planet to harbor life.** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"Generate some factual information to complete the following in 2-3 lines:\n",
    "                In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aba55e-c0a3-416e-8c94-4ac1ffeae39c",
   "metadata": {},
   "source": [
    "## **Adding a System Prompt**\n",
    "\n",
    "**Important Note:** System Prompt can be specified using `system_instruction`. `system_instruction` is not enabled for models/gemini-pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b18e562-75f5-4eb0-a312-f7a30fccbec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In our solar system, Earth is a **rocky planet with a dynamic surface**, home to a vast diversity of life. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\", \n",
    "                              system_instruction=\"\"\"Generate some factual information to complete the user input. \n",
    "                              Completion must have maximum 2-3 lines.\"\"\")\n",
    "\n",
    "user_prompt = \"\"\"In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1edeb-1b26-471e-a008-f78a5774f545",
   "metadata": {},
   "source": [
    "## **Important Parameters**\n",
    "\n",
    "If you run the above code few times, you will notice that the output changes across runs. Generative models are **non-deterministic**. This means that even with the same input they can produce different outputs. This behavior allows for creativity and diversity in the generated outputs, which can be great when trying to generate different creative styles. There are parameters which can help us control this behavior like temperature, top_p, etc...\n",
    "\n",
    "- **candidate_count:** This controls the number of responses that will be generated for a single prompt. Default value is 1. Increasing this will generate more text responses. This increase the resource usage.\n",
    "- **stop_sequence:** It allows to specify a list of strings that will act as stopsigns for the model.\n",
    "- **max_output_tokens:** This is the maximum number of tokens the model will generate in the response.\n",
    "- **temperature:** It act as a control knob that influences the randomness of the model's output. A higher temperature value will result in a more varied and creative response. Lower values would be more effective in returning predictable results with an LLM.\n",
    "- **top_p:** Range from [0.0, 1.0]. This is also known a **nucleus sampling**. The LLM only considers the next word options that cumulatively add up to a probability of reaching or exceeding the `top_p` value. A higher value will create looser threshold. This will allow the model to consider a wider range of probable options while still prioritizing the most likely ones. A lower `top_p` value will create a stricter threshold, leading to less diverse and more predictable outputs.\n",
    "- **top_k:** This parameter limits the number of possible next words to the `k` most probable options based on the probability distribution. A lower `k` value restricts the selection to a smaller pool of the most likely words, leading to less diverse and more predictable outputs.\n",
    "\n",
    "Both `top_p` and `top_k` works in conjunction with the `temperature` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7389c3fa-5e03-435c-87c0-e044f16e5f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Feature Selection in Data Science: A Comprehensive Explanation\n",
      "\n",
      "Feature selection is a crucial step in data science, particularly in machine learning. It involves **identifying and choosing the most relevant features (variables) from a dataset to use in model building**.  This process is essential for several reasons:\n",
      "\n",
      "**Benefits of Feature Selection:**\n",
      "\n",
      "* **Improved Model Performance:**  By removing irrelevant or redundant features, we reduce noise and complexity in the dataset. This leads to more accurate and efficient models.\n",
      "* **Reduced Overfitting:**  Overfitting occurs when a model learns the training data too well and performs poorly on unseen data. Feature selection helps prevent overfitting by focusing on the most informative features.\n",
      "* **Simplified Models:**  Fewer features mean simpler models that are easier to understand, interpret, and deploy.\n",
      "* **Faster Training and Inference:**  With fewer features, models require less computational resources for training and making predictions, leading to faster execution times.\n",
      "* **Reduced Costs:**  Less data storage and processing requirements can significantly reduce costs, especially for large datasets.\n",
      "\n",
      "**Types of Feature Selection Methods:**\n",
      "\n",
      "Feature selection techniques can be broadly categorized into three main approaches:\n",
      "\n",
      "1. **Filter Methods:**  These methods use statistical tests or measures to evaluate the relevance\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Setting our parameters\n",
    "custom_config = genai.types.GenerationConfig(max_output_tokens=256, temperature=1.0)\n",
    "\n",
    "user_prompt = \"\"\"What is feature selection in data science? Explain in detail.\"\"\"\n",
    "\n",
    "# Passing our custom parameters to the generate_content method\n",
    "response = model.generate_content(user_prompt, generation_config=custom_config)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0759e05-8add-4642-9597-95aac41cb3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Feature Selection: The Art of Choosing the Right Variables\n",
      "\n",
      "In data science, feature selection is a crucial process that involves **identifying and selecting the most relevant features (variables) from a dataset** for building a predictive model. It's like choosing the right ingredients for a recipe â€“ the wrong ones can ruin the dish, while the right ones create a masterpiece.\n",
      "\n",
      "**Why is Feature Selection Important?**\n",
      "\n",
      "* **Improved Model Performance:** Irrelevant or redundant features can introduce noise and complexity, hindering model accuracy and generalization. Selecting the right features can lead to simpler, more interpretable, and more accurate models.\n",
      "* **Reduced Overfitting:** Overfitting occurs when a model learns the training data too well, failing to generalize to unseen data. Feature selection helps prevent this by reducing the number of features, thus reducing the model's complexity.\n",
      "* **Faster Training and Deployment:** Fewer features mean less data to process, leading to faster model training and deployment.\n",
      "* **Enhanced Interpretability:** Models with fewer features are easier to understand and interpret, making it easier to identify the key factors driving predictions.\n",
      "\n",
      "**Types of Feature Selection Techniques:**\n",
      "\n",
      "There are three main categories of feature selection techniques:\n",
      "\n",
      "1. **Filter Methods:** These methods evaluate features independently based on their intrinsic properties, without considering the model. Examples include:\n",
      "    * **Univariate Feature Selection:** Measures the relationship between each feature and the target variable using statistical tests like chi-squared, ANOVA, or correlation coefficients.\n",
      "    * **Variance Threshold:** Removes features with low variance, as they are unlikely to contribute significantly to the model.\n",
      "2. **Wrapper Methods:** These methods use a specific machine learning model to evaluate the performance of different feature subsets. They are more computationally expensive but can lead to better results. Examples include:\n",
      "    * **Recursive Feature Elimination (RFE):** Iteratively removes features based on their importance scores until a desired number of features remains.\n",
      "    * **Forward Feature Selection:** Starts with an empty set of features and iteratively adds the feature that improves the model performance the most.\n",
      "    * **Backward Feature Selection:** Starts with all features and iteratively removes the feature that has the least impact on the model performance.\n",
      "3. **Embedded Methods:** These methods incorporate feature selection as part of the model training process. They are often more efficient and can provide insights into feature importance. Examples include:\n",
      "    * **Lasso Regression:** A linear regression model that uses L1 regularization to shrink the coefficients of less important features towards zero.\n",
      "    * **Decision Trees:** These models inherently perform feature selection by splitting nodes based on the most informative features.\n",
      "    * **Random Forest:** An ensemble of decision trees that can be used to identify important features based on their frequency of selection across trees.\n",
      "\n",
      "**Choosing the Right Technique:**\n",
      "\n",
      "The best feature selection technique depends on the specific dataset, the model being used, and the desired trade-off between performance and interpretability.\n",
      "\n",
      "* **Filter methods** are often a good starting point for quickly reducing the number of features.\n",
      "* **Wrapper methods** can be more effective but are computationally expensive.\n",
      "* **Embedded methods** offer a good balance between performance and efficiency.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Feature selection is a crucial step in building effective machine learning models. By carefully selecting the most relevant features, we can improve model performance, reduce overfitting, and enhance interpretability. Choosing the right technique depends on the specific context and the desired trade-offs.\n"
     ]
    }
   ],
   "source": [
    "# Setting our parameters\n",
    "custom_config = genai.types.GenerationConfig(temperature=0.1, top_p=0.1, top_k=32)\n",
    "\n",
    "user_prompt = \"\"\"What is feature selection in data science? Explain in detail.\"\"\"\n",
    "\n",
    "# Passing our custom parameters to the generate_content method\n",
    "response = model.generate_content(user_prompt, generation_config=custom_config)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
