{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4089c9-645a-43b1-bd0e-ca87264b5306",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Optimizing RAGs**\n",
    "1. Optimizing Indexing - \n",
    "2. Optimizing Quering - MultiQuery Retriever\n",
    "3. Optimizing Post Retrieval Process - Contextual Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb32265-4c2b-46d6-940e-f3a047ae7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d28f5c-ccb4-44f5-af03-d90b192e7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Initialize an embedding_model\n",
    "# We are just loading OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ba669a-9f7a-428a-b8f7-986d63ae0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Initialize a ChromaDB Connection\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# We can check the already existing values\n",
    "print(len(db.get()[\"ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3afd82-93dd-4642-938f-33227644e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db connection to Retriever Object\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd51913-da64-456b-be7b-f9905e47fe90",
   "metadata": {},
   "source": [
    "## **MultiQuery Retriever**\n",
    "\n",
    "- Sometimes the documents in your vector store may contain phrasing that you are not aware of, due to their size. This can cause issues in trying to think of the correct query string for similarity search.\n",
    "- Retrieval may produce different results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems.\n",
    "- The **`MultiQueryRetriever`** automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. \n",
    "- For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the **`MultiQueryRetriever`** might be able to overcome some of the limitations of the distance-based retrieval and get a richer set of results.\n",
    "\n",
    "**Idea**  \n",
    "- We will typically ask a question/query\n",
    "- A ChatModel is going to make a couple of variations of the initial question/query\n",
    "- These variations are now used to retrieve the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23df2fd3-134f-43b8-a38e-d4e3ce369a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5fe10b-8476-45ad-9679-17509397fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "mq_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever = retriever, \n",
    "    llm = chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dc96921-129f-4a19-a489-b82999a5489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging: Behind the scenes\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129235f0-6156-4943-b4a3-ce301eb6d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How does Julie compare to Rachel on the list?', '2. What are the differences between Julie and Rachel on the list?', \"3. Can you provide insights on Julie and Rachel's positions on the list?\"]\n"
     ]
    }
   ],
   "source": [
    "question = \"What is their on Julie vs Rachels List?\"\n",
    "\n",
    "# This will not directly answer any query\n",
    "unique_docs = mq_retriever.invoke(input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afae6c08-6b45-40eb-aaa4-8bf1fa5efd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e5f1e9e-bd7e-48f6-a9f8-9b3317ed9ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"149\\n00:08:53,839 --> 00:08:55,067\\nI mean....\\n\\n150\\n00:08:55,274 --> 00:08:59,802\\nAll right, I guess you can say\\nshe's a little spoiled sometimes.\\n\\n151\\n00:09:00,245 --> 00:09:01,940\\nYou could say that.\\n\\n152\\n00:09:03,816 --> 00:09:07,775\\nI guess, sometimes\\nshe's a little ditzy, you know?\\n\\n153\\n00:09:08,153 --> 00:09:11,088\\nAnd I've seen her be a little\\ntoo into her looks.\\n\\n154\\n00:09:11,757 --> 00:09:13,816\\nAnd Julie and I have\\na lot in common...\\n\\n155\\n00:09:14,092 --> 00:09:16,959\\n... because we're both\\npaleontologists, right?\\n\\n156\\n00:09:17,196 --> 00:09:19,027\\nBut Rachel's just a waitress.\\n\\n157\\n00:09:19,264 --> 00:09:20,663\\nWaitress.\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"152\\n00:09:03,816 --> 00:09:07,775\\nI guess, sometimes\\nshe's a little ditzy, you know?\\n\\n153\\n00:09:08,153 --> 00:09:11,088\\nAnd I've seen her be a little\\ntoo into her looks.\\n\\n154\\n00:09:11,757 --> 00:09:13,816\\nAnd Julie and I have\\na lot in common...\\n\\n155\\n00:09:14,092 --> 00:09:16,959\\n... because we're both\\npaleontologists, right?\\n\\n156\\n00:09:17,196 --> 00:09:19,027\\nBut Rachel's just a waitress.\\n\\n157\\n00:09:19,264 --> 00:09:20,663\\nWaitress.\\n\\n158\\n00:09:21,200 --> 00:09:23,191\\nGot it.\\nYou guys want to play Doom?\\n\\n159\\n00:09:25,938 --> 00:09:27,997\\nOr we could keep doing this.\\n\\n160\\n00:09:29,775 --> 00:09:30,969\\nWhat else?\\n\\n161\\n00:09:31,610 --> 00:09:32,941\\nI don't know.\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"145\\n00:08:42,594 --> 00:08:44,425\\nNo, Amish boy.\\n\\n146\\n00:08:46,398 --> 00:08:50,061\\nLet's start with the cons\\nbecause they're more fun.\\n\\n147\\n00:08:50,335 --> 00:08:51,165\\nRachel first.\\n\\n148\\n00:08:52,171 --> 00:08:53,331\\nI don't know.\\n\\n149\\n00:08:53,839 --> 00:08:55,067\\nI mean....\\n\\n150\\n00:08:55,274 --> 00:08:59,802\\nAll right, I guess you can say\\nshe's a little spoiled sometimes.\\n\\n151\\n00:09:00,245 --> 00:09:01,940\\nYou could say that.\\n\\n152\\n00:09:03,816 --> 00:09:07,775\\nI guess, sometimes\\nshe's a little ditzy, you know?\\n\\n153\\n00:09:08,153 --> 00:09:11,088\\nAnd I've seen her be a little\\ntoo into her looks.\\n\\n154\\n00:09:11,757 --> 00:09:13,816\\nAnd Julie and I have\\na lot in common...\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x04.srt'}, page_content=\"233\\n00:16:32,347 --> 00:16:34,577\\nCome on, it's only 1 1 :30.\\n\\n234\\n00:16:34,850 --> 00:16:38,911\\nLet's just talk. We never just\\nhang out and talk anymore.\\n\\n235\\n00:16:39,221 --> 00:16:41,655\\nRachel, that's all we do.\\n\\n236\\n00:16:43,358 --> 00:16:46,020\\nMaybe that's all we do.\\nWhat about Julie?\\n\\n237\\n00:16:47,362 --> 00:16:48,920\\nWhat about Julie?\\n\\n238\\n00:16:49,364 --> 00:16:53,164\\nYou have been in our lives\\nfor nearly two months now...\\n\\n239\\n00:16:53,769 --> 00:16:55,669\\n...and we don't really know you.\\n\\n240\\n00:16:55,904 --> 00:16:57,428\\nI mean, who is Julie?\\n\\n241\\n00:16:58,941 --> 00:17:01,068\\nWhat do you like?\\nWhat don't you like?\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x04.srt'}, page_content=\"236\\n00:16:43,358 --> 00:16:46,020\\nMaybe that's all we do.\\nWhat about Julie?\\n\\n237\\n00:16:47,362 --> 00:16:48,920\\nWhat about Julie?\\n\\n238\\n00:16:49,364 --> 00:16:53,164\\nYou have been in our lives\\nfor nearly two months now...\\n\\n239\\n00:16:53,769 --> 00:16:55,669\\n...and we don't really know you.\\n\\n240\\n00:16:55,904 --> 00:16:57,428\\nI mean, who is Julie?\\n\\n241\\n00:16:58,941 --> 00:17:01,068\\nWhat do you like?\\nWhat don't you like?\\n\\n242\\n00:17:01,276 --> 00:17:03,506\\nWe want to know everything.\\n\\n243\\n00:17:03,846 --> 00:17:05,746\\nWell, that could take awhile.\\n\\n244\\n00:17:06,348 --> 00:17:07,508\\nSo?\\n\\n245\\n00:17:09,118 --> 00:17:12,519\\nWho here does not have\\nthe time to get to know Julie?\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='136\\n00:08:08,169 --> 00:08:10,967\\nRoss, listen.\\nI got two words for you:\\n\\n137\\n00:08:11,239 --> 00:08:12,399\\nThreesome.\\n\\n138\\n00:08:18,399 --> 00:08:20,599\\nYou still have another word if you have not use.\\n\\n139\\n00:08:21,899 --> 00:08:25,399\\nHey, I think I know what is it, HELP!\\n\\n140\\n00:08:25,644 --> 00:08:28,408\\nLet\\'s get logical about this.\\nWe\\'ll make a list.\\n\\n141\\n00:08:28,614 --> 00:08:31,048\\n\"Rachel and Julie: Pros and Cons.\"\\n\\n142\\n00:08:35,254 --> 00:08:37,984\\nWe\\'ll put their names\\nin different fonts...\\n\\n143\\n00:08:38,223 --> 00:08:40,657\\n...and I can use different\\ncolors for each column.\\n\\n144\\n00:08:41,093 --> 00:08:42,287\\nCan\\'t we use a pen?')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84471a9a-b77d-477b-bdc4-1b866d46cb29",
   "metadata": {},
   "source": [
    "## **Contextual Compression**\n",
    "\n",
    "We just saw how to leverage LLMs to expand our queries, now let's explore how to use LLMs to \"compress\" our outputs.\n",
    "\n",
    "Above we returned the entirety of the vectorized document. Ideally we would pass this document as context to an LLM to get a more relevant (i.e. compressed) answer.\n",
    "\n",
    "**Important: We are not performing compression in the traditional sense, instead we are using an LLM to grab a larger document text output and \"distill\" it to a smaller and more relevant output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a0a63c-de4d-4824-ae69-3347b52812fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Create a instance of chain extractor\n",
    "# This with compress the large document into a summary\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "compressor = LLMChainExtractor.from_llm(chat_model)\n",
    "\n",
    "# Contextual Compressions\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29105bd2-d416-4e3d-8127-88627f7ecb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How does Julie compare to Rachel on the list?\"\n",
    "\n",
    "# This will not directly answer any query\n",
    "compressed_docs = compression_retriever.invoke(input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e712ec65-c557-490c-a8bc-12c2cdb813d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(compressed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d732fd-5ce1-4950-8e42-3ca2a2aae7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"But Rachel's just a waitress.\"),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='And Julie and I have\\na lot in common')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb03889b-ee94-45d7-a74a-8fa2de0d2bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"But Rachel's just a waitress.\", 'And Julie and I have\\na lot in common']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returning the summary of the compressed_docs\n",
    "\n",
    "[docs.page_content for docs in compressed_docs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
