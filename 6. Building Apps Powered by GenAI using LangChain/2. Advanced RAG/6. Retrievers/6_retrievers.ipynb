{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4089c9-645a-43b1-bd0e-ca87264b5306",
   "metadata": {},
   "source": [
    "# **Vector Stores and Retrievers**\n",
    "\n",
    "## **What's Covered?**\n",
    "- Retrievers\n",
    "- Multi-Query Retrievers\n",
    "- Contextual Compressions\n",
    "- Indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e66673-87a3-4a22-be85-61c9bb98d4c5",
   "metadata": {},
   "source": [
    "## **Retrievers**\n",
    "\n",
    "There are times when we need to pass in Vector Stores as **retriever** objects, which can be easily done via a **as_retriever()** method call.\n",
    "\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well.\n",
    "\n",
    "Retrievers accept a string query as input and return a list of Document's as output.\n",
    "\n",
    "We can specify search type implemented by a vector store, like similarity and MMR (i.e. Maximum marginal relevance retrieval), to query the texts in the vector store.\n",
    "- **Specify Top k**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 3})\n",
    "```\n",
    "- **Specify Top k and Search Type**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "```\n",
    "- **Maximum Marginal Relevance Retrieval**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_type=\"mmr\")\n",
    "```\n",
    "- **Similarity Score Threshold Retrieval**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"score_threshold\": 0.5}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec1f390-9fed-40b8-879e-9bc3453960f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8959bd-6941-4914-997b-e281d960636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Initialize an embedding_model\n",
    "# We are just loading OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003917d7-9320-49f0-837f-b9e3fd9508d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Initialize a ChromaDB Connection\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60dbda2-ca2e-4bbd-a823-e0a4db5dac61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1165ee8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dface206-7bd5-411f-bdd0-16ccf5249fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "# We can check the already existing values\n",
    "\n",
    "print(len(db.get()[\"ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a35b26-5257-470b-a47b-41aa1a5206cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db connection to Retriever Object\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc99fd78-8b1a-46d9-8bb3-02f04435f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is their on Julie vs Rachels List?\"\n",
    "\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f4243f-0873-4645-803b-45608fe1929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='126\\n00:07:28,029 --> 00:07:29,621\\nHe\\'s gonna stay with Julie.\\n\\n127\\n00:07:29,864 --> 00:07:31,957\\nHe\\'s gonna stay with her\\nand she\\'ll be:\\n\\n128\\n00:07:32,233 --> 00:07:34,463\\n\"Hi, I\\'m Julie. Ross picked me.\\n\\n129\\n00:07:34,736 --> 00:07:38,797\\nWe\\'ll get married and have lots\\nof kids and dig up stuff together!\"\\n\\n130\\n00:07:40,475 --> 00:07:43,137\\nNo offense, but that\\nsounds nothing like her.\\n\\n131\\n00:07:46,080 --> 00:07:50,073\\nWhat am I gonna do?\\nThis is like a complete nightmare!\\n\\n132\\n00:07:50,318 --> 00:07:54,448\\nI know. This must be so hard.\\n\"Oh, no! Two women love me!\\n\\n133\\n00:07:55,790 --> 00:07:59,055\\nThey\\'re both gorgeous,\\nmy wallet\\'s too small for my 50s...\\n\\n134\\n00:07:59,260 --> 00:08:01,751\\n...and my diamond shoes are too tight!\"'),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='247\\n00:15:09,082 --> 00:15:10,242\\nNo! I\\n\\n248\\n00:15:10,483 --> 00:15:13,611\\nOkay, look at the other side.\\nLook at Julie\\'s column.\\n\\n249\\n00:15:14,487 --> 00:15:15,954\\n\"She\\'s not Rachem\"?\\n\\n250\\n00:15:17,423 --> 00:15:18,822\\nWhat the hell\\'s a Rachem?\\n\\n251\\n00:15:19,125 --> 00:15:21,150\\nIs that a stupid paleontology word...\\n\\n252\\n00:15:21,394 --> 00:15:23,726\\n... I wouldn\\'t know,\\nbecause I\\'m just a waitress?\\n\\n253\\n00:15:24,297 --> 00:15:25,787\\nRach, come on!\\n\\n254\\n00:15:28,001 --> 00:15:29,832\\nIt\\'s \"She\\'s not Rachel\"!\\n\\n255\\n00:15:30,103 --> 00:15:31,934\\nShe\\'s not....\\n\\n256\\n00:15:39,913 --> 00:15:41,278\\nMy diary! Brilliant!'),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"145\\n00:08:42,594 --> 00:08:44,425\\nNo, Amish boy.\\n\\n146\\n00:08:46,398 --> 00:08:50,061\\nLet's start with the cons\\nbecause they're more fun.\\n\\n147\\n00:08:50,335 --> 00:08:51,165\\nRachel first.\\n\\n148\\n00:08:52,171 --> 00:08:53,331\\nI don't know.\\n\\n149\\n00:08:53,839 --> 00:08:55,067\\nI mean....\\n\\n150\\n00:08:55,274 --> 00:08:59,802\\nAll right, I guess you can say\\nshe's a little spoiled sometimes.\\n\\n151\\n00:09:00,245 --> 00:09:01,940\\nYou could say that.\\n\\n152\\n00:09:03,816 --> 00:09:07,775\\nI guess, sometimes\\nshe's a little ditzy, you know?\\n\\n153\\n00:09:08,153 --> 00:09:11,088\\nAnd I've seen her be a little\\ntoo into her looks.\\n\\n154\\n00:09:11,757 --> 00:09:13,816\\nAnd Julie and I have\\na lot in common...\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd51913-da64-456b-be7b-f9905e47fe90",
   "metadata": {},
   "source": [
    "## **MultiQuery Retriever**\n",
    "\n",
    "- Sometimes the documents in your vector store may contain phrasing that you are not aware of, due to their size. This can cause issues in trying to think of the correct query string for similarity search.\n",
    "- Retrieval may produce different results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems.\n",
    "- The **`MultiQueryRetriever`** automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. \n",
    "- For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the **`MultiQueryRetriever`** might be able to overcome some of the limitations of the distance-based retrieval and get a richer set of results.\n",
    "\n",
    "**Idea**  \n",
    "- We will typically ask a question/query\n",
    "- A ChatModel is going to make a couple of variations of the initial question/query\n",
    "- These variations are now used to retrieve the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23df2fd3-134f-43b8-a38e-d4e3ce369a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) \n",
    "\n",
    "db_connection = Chroma(\n",
    "    persist_directory=\"./chroma_db_\", \n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc5fe10b-8476-45ad-9679-17509397fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever = db_connection.as_retriever(), \n",
    "    llm = chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc96921-129f-4a19-a489-b82999a5489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging: Behind the scenes\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "129235f0-6156-4943-b4a3-ce301eb6d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is known about Rachel?', '2. Can you provide information on Rachel?', '3. Who is the person named Rachel?']\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Rachel?\"\n",
    "\n",
    "# This will not directly answer any query\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afae6c08-6b45-40eb-aaa4-8bf1fa5efd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08abde30-620f-4b99-888e-2fdc6ccd0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "00:03:37,400 --> 00:03:40,808\n",
      "Everybody, this is Rachel,\n",
      "another Lincoln High survivor.\n",
      "\n",
      "50\n",
      "00:03:41,703 --> 00:03:44,089\n",
      "This is everybody.\n",
      "Chandler and Phoebe..\n",
      "\n",
      "51\n",
      "00:03:44,841 --> 00:03:46,509\n",
      "...and Joey. And remember\n",
      "my brother, Ross?\n",
      "\n",
      "52\n",
      "00:03:47,211 --> 00:03:47,574\n",
      "Sure!\n",
      "\n",
      "53\n",
      "00:03:56,832 --> 00:03:59,845\n",
      "You want to tell us now, or are we\n",
      "waiting for four wet bridesmaids?\n",
      "\n",
      "54\n",
      "00:04:02,277 --> 00:04:05,575\n",
      "Oh, God! Well, it started about\n",
      "a half-hour before the wedding.\n",
      "\n",
      "55\n",
      "00:04:07,196 --> 00:04:09,015\n",
      "I was in this room with\n",
      "all the presents...\n",
      "\n",
      "56\n",
      "00:04:10,046 --> 00:04:14,346\n",
      "This really gorgeous\n",
      "Limoges gravy boat.\n",
      "\n",
      "57\n",
      "00:04:14,976 --> 00:04:15,572\n",
      "When all of a sudden I realize...\n"
     ]
    }
   ],
   "source": [
    "print(unique_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e5f1e9e-bd7e-48f6-a9f8-9b3317ed9ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='49\\n00:03:37,400 --> 00:03:40,808\\nEverybody, this is Rachel,\\nanother Lincoln High survivor.\\n\\n50\\n00:03:41,703 --> 00:03:44,089\\nThis is everybody.\\nChandler and Phoebe..\\n\\n51\\n00:03:44,841 --> 00:03:46,509\\n...and Joey. And remember\\nmy brother, Ross?\\n\\n52\\n00:03:47,211 --> 00:03:47,574\\nSure!\\n\\n53\\n00:03:56,832 --> 00:03:59,845\\nYou want to tell us now, or are we\\nwaiting for four wet bridesmaids?\\n\\n54\\n00:04:02,277 --> 00:04:05,575\\nOh, God! Well, it started about\\na half-hour before the wedding.\\n\\n55\\n00:04:07,196 --> 00:04:09,015\\nI was in this room with\\nall the presents...\\n\\n56\\n00:04:10,046 --> 00:04:14,346\\nThis really gorgeous\\nLimoges gravy boat.\\n\\n57\\n00:04:14,976 --> 00:04:15,572\\nWhen all of a sudden I realize...', metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content=\"121\\n00:07:59,047 --> 00:08:02,091\\n. . .everybody.\\nEverybody, this is Paul.\\n\\n122\\n00:08:02,711 --> 00:08:07,156\\n-The wine guy.\\n-I didn't catch your name. Paul?\\n\\n123\\n00:08:08,418 --> 00:08:09,633\\nChange. Sit down.\\nTwo seconds.\\n\\n124\\n00:08:13,819 --> 00:08:16,715\\nI just pulled out four eyelashes.\\nThat can't be good.\\n\\n125\\n00:08:19,661 --> 00:08:21,438\\nRachel, what are you\\nup to tonight?\\n\\n126\\n00:08:22,276 --> 00:08:26,091\\nI was supposed to be headed\\nfor Aruba on my honeymoon. . .\\n\\n127\\n00:08:26,436 --> 00:08:27,826\\n. . .so, nothing.\\n\\n128\\n00:08:29,371 --> 00:08:31,279\\nRight. You're not even\\ngetting your honeymoon.\\n\\n129\\n00:08:31,766 --> 00:08:36,419\\nAlthough, Aruba. This time of year?\\nTalk about your. . .\", metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content=\"118\\n00:07:46,366 --> 00:07:47,723\\nThat'd be good.\\n\\n119\\n00:07:49,454 --> 00:07:51,868\\n-Really?\\n-Go on! It's Paul, the wine guy!\\n\\n120\\n00:07:56,089 --> 00:07:58,468\\nHi, come in! Paul, this is. . .\\n\\n121\\n00:07:59,047 --> 00:08:02,091\\n. . .everybody.\\nEverybody, this is Paul.\\n\\n122\\n00:08:02,711 --> 00:08:07,156\\n-The wine guy.\\n-I didn't catch your name. Paul?\\n\\n123\\n00:08:08,418 --> 00:08:09,633\\nChange. Sit down.\\nTwo seconds.\\n\\n124\\n00:08:13,819 --> 00:08:16,715\\nI just pulled out four eyelashes.\\nThat can't be good.\\n\\n125\\n00:08:19,661 --> 00:08:21,438\\nRachel, what are you\\nup to tonight?\\n\\n126\\n00:08:22,276 --> 00:08:26,091\\nI was supposed to be headed\\nfor Aruba on my honeymoon. . .\", metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content=\"35\\n00:02:47,773 --> 00:02:49,431\\nSometimes I wish I was a lesbian.\\n\\n36\\n00:02:51,783 --> 00:02:52,886\\nDid I say that out loud?\\n\\n37\\n00:02:55,748 --> 00:02:59,027\\nLook, you're feeling\\na lot of pain right now.\\n\\n38\\n00:02:59,915 --> 00:03:01,192\\nYou're angry. You're hurting.\\n\\n39\\n00:03:02,321 --> 00:03:02,903\\nCan I tell you what\\nthe answer is?\\n\\n40\\n00:03:04,771 --> 00:03:05,652\\nStrip joints!\\n\\n41\\n00:03:10,515 --> 00:03:12,091\\nSee, but I don't want\\nto be single, okay?\\n\\n42\\n00:03:12,875 --> 00:03:14,662\\nI just want to be married again.\\n\\n43\\n00:03:19,124 --> 00:03:21,327\\nAnd I just want a million dollars!\\n\\n44\\n00:03:23,860 --> 00:03:24,782\\nRachel?\", metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content='46\\n00:03:28,955 --> 00:03:29,746\\nI went to your building and\\nthis guy with a hammer said...\\n\\n47\\n00:03:30,581 --> 00:03:31,479\\n...that you might be here and you are.\\n\\n48\\n00:03:33,668 --> 00:03:35,097\\n-Can I get you some coffee?\\n-Decaf.\\n\\n49\\n00:03:37,400 --> 00:03:40,808\\nEverybody, this is Rachel,\\nanother Lincoln High survivor.\\n\\n50\\n00:03:41,703 --> 00:03:44,089\\nThis is everybody.\\nChandler and Phoebe..\\n\\n51\\n00:03:44,841 --> 00:03:46,509\\n...and Joey. And remember\\nmy brother, Ross?\\n\\n52\\n00:03:47,211 --> 00:03:47,574\\nSure!\\n\\n53\\n00:03:56,832 --> 00:03:59,845\\nYou want to tell us now, or are we\\nwaiting for four wet bridesmaids?\\n\\n54\\n00:04:02,277 --> 00:04:05,575\\nOh, God! Well, it started about\\na half-hour before the wedding.', metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content=\"38\\n00:02:59,915 --> 00:03:01,192\\nYou're angry. You're hurting.\\n\\n39\\n00:03:02,321 --> 00:03:02,903\\nCan I tell you what\\nthe answer is?\\n\\n40\\n00:03:04,771 --> 00:03:05,652\\nStrip joints!\\n\\n41\\n00:03:10,515 --> 00:03:12,091\\nSee, but I don't want\\nto be single, okay?\\n\\n42\\n00:03:12,875 --> 00:03:14,662\\nI just want to be married again.\\n\\n43\\n00:03:19,124 --> 00:03:21,327\\nAnd I just want a million dollars!\\n\\n44\\n00:03:23,860 --> 00:03:24,782\\nRachel?\\n\\n45\\n00:03:25,383 --> 00:03:28,313\\nOh, God, Monica!\\nHi! Thank God!\\n\\n46\\n00:03:28,955 --> 00:03:29,746\\nI went to your building and\\nthis guy with a hammer said...\\n\\n47\\n00:03:30,581 --> 00:03:31,479\\n...that you might be here and you are.\", metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content=\"115\\n00:07:39,134 --> 00:07:41,271\\nRach, I can cancel.\\n\\n116\\n00:07:41,491 --> 00:07:42,604\\nOh, God. Please, no.\\nGo, I'll be fine.\\n\\n117\\n00:07:42,899 --> 00:07:44,822\\nRoss are you okay?\\nDo you want me to stay?\\n\\n118\\n00:07:46,366 --> 00:07:47,723\\nThat'd be good.\\n\\n119\\n00:07:49,454 --> 00:07:51,868\\n-Really?\\n-Go on! It's Paul, the wine guy!\\n\\n120\\n00:07:56,089 --> 00:07:58,468\\nHi, come in! Paul, this is. . .\\n\\n121\\n00:07:59,047 --> 00:08:02,091\\n. . .everybody.\\nEverybody, this is Paul.\\n\\n122\\n00:08:02,711 --> 00:08:07,156\\n-The wine guy.\\n-I didn't catch your name. Paul?\\n\\n123\\n00:08:08,418 --> 00:08:09,633\\nChange. Sit down.\\nTwo seconds.\", metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84471a9a-b77d-477b-bdc4-1b866d46cb29",
   "metadata": {},
   "source": [
    "## **Contextual Compression**\n",
    "\n",
    "We just saw how to leverage LLMs to expand our queries, now let's explore how to use LLMs to \"compress\" our outputs.\n",
    "\n",
    "Above we returned the entirety of the vectorized document. Ideally we would pass this document as context to an LLM to get a more relevant (i.e. compressed) answer.\n",
    "\n",
    "**Important: We are not performing compression in the traditional sense, instead we are using an LLM to grab a larger document text output and \"distill\" it to a smaller and more relevant output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87a0a63c-de4d-4824-ae69-3347b52812fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Create a instance of chain extractor\n",
    "# This with compress the large document into a summary\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "compressor = LLMChainExtractor.from_llm(chat_model)\n",
    "\n",
    "# Contextual Compressions\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=db_connection.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29105bd2-d416-4e3d-8127-88627f7ecb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Rachel?\"\n",
    "\n",
    "# This will not directly answer any query\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e712ec65-c557-490c-a8bc-12c2cdb813d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(compressed_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86d732fd-5ce1-4950-8e42-3ca2a2aae7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Rachel, another Lincoln High survivor.', metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content='Rachel', metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'}),\n",
       " Document(page_content='Rachel, what are you\\nup to tonight?', metadata={'source': 'data/subtitles_data/Friends - 1x01 - The One Where Monica Gets A Roommate.720p HDTV.TvR.en.srt'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb03889b-ee94-45d7-a74a-8fa2de0d2bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rachel, another Lincoln High survivor.',\n",
       " 'Rachel',\n",
       " 'Rachel, what are you\\nup to tonight?']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returning the summary of the compressed_docs\n",
    "\n",
    "[docs.page_content for docs in compressed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058bb1c-9407-4e6d-bae2-cf85ef53e2f8",
   "metadata": {},
   "source": [
    "## **Indexing (coming soon...)**\n",
    "\n",
    "The indexing API lets you load and keep in sync documents from any source into a vector store. Specifically, it helps:\n",
    "\n",
    "- Avoid writing duplicated content into the vector store\n",
    "- Avoid re-writing unchanged content\n",
    "- Avoid re-computing embeddings over unchanged content\n",
    "\n",
    "All of which should save you time and money, as well as improve your vector search results.\n",
    "\n",
    "### **How it works?**\n",
    "LangChain indexing makes use of a record manager (`RecordManager`) that keeps track of document writes into the vector store.\n",
    "When indexing content, hashes are computed for each document, and the following information is stored in the record manager:\n",
    "- the document hash (hash of both page content and metadata)\n",
    "- write time\n",
    "- the source id â€“ each document should include information in its metadata to allow us to determine the ultimate source of this document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb99f0-e25f-4f61-a9a6-7ca8a88751d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.indexes import SQLRecordManager, index\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) \n",
    "\n",
    "# db_connection = Chroma(\n",
    "#     persist_directory=\"./chroma_db_\", \n",
    "#     embedding_function=embedding_model\n",
    "#     index_name=\"test_index\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
