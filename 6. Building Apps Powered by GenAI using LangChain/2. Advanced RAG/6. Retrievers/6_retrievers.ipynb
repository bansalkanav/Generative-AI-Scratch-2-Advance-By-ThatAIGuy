{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4089c9-645a-43b1-bd0e-ca87264b5306",
   "metadata": {},
   "source": [
    "# **Retrievers**\n",
    "\n",
    "## **What's Covered?**\n",
    "- Introduction to Retrievers\n",
    "    - Specify Top k\n",
    "    - Specify Top k and Search Type\n",
    "    - Maximum Marginal Relevance Retrieval\n",
    "    - Similarity Score Threshold Retrieval\n",
    "- Building an End-to-End RAG Chain\n",
    "    - Step 1: Initialize the Chroma DB Connection\n",
    "    - Step 2: Create a Retriever Object\n",
    "    - Step 3: Initialize a Chat Prompt Template\n",
    "    - Step 4: Initialize a Generator (i.e. Chat Model)\n",
    "    - Step 5: Initialize a Output Parser\n",
    "    - Step 6: Define a RAG Chain\n",
    "    - Step 7: Invoke the Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e66673-87a3-4a22-be85-61c9bb98d4c5",
   "metadata": {},
   "source": [
    "## **Introduction to Retrievers**\n",
    "\n",
    "There are times when we need to pass in Vector Stores as **retriever** objects, which can be easily done via a **as_retriever()** method call.\n",
    "\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well.\n",
    "\n",
    "Retrievers accept a string query as input and return a list of Document's as output.\n",
    "\n",
    "We can specify search type implemented by a vector store, like similarity and MMR (i.e. Maximum marginal relevance retrieval), to query the texts in the vector store.\n",
    "- **Specify Top k**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 3})\n",
    "```\n",
    "- **Specify Top k and Search Type**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "```\n",
    "- **Maximum Marginal Relevance Retrieval**\n",
    "```python\n",
    "retriever = db_connection.as_retriever(search_type=\"mmr\")\n",
    "```\n",
    "- **Similarity Score Threshold Retrieval**  \n",
    "Apply a cutoff or a threshold such that any document which is below the cutoff is not returned.\n",
    "```python\n",
    "retriever = db_connection.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec1f390-9fed-40b8-879e-9bc3453960f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8959bd-6941-4914-997b-e281d960636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Initialize an embedding_model\n",
    "# We are just loading OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003917d7-9320-49f0-837f-b9e3fd9508d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Initialize a ChromaDB Connection\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60dbda2-ca2e-4bbd-a823-e0a4db5dac61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1165ae7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dface206-7bd5-411f-bdd0-16ccf5249fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "# We can check the already existing values\n",
    "\n",
    "print(len(db.get()[\"ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a35b26-5257-470b-a47b-41aa1a5206cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db connection to Retriever Object\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc99fd78-8b1a-46d9-8bb3-02f04435f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is their on Julie vs Rachels List?\"\n",
    "\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f4243f-0873-4645-803b-45608fe1929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='126\\n00:07:28,029 --> 00:07:29,621\\nHe\\'s gonna stay with Julie.\\n\\n127\\n00:07:29,864 --> 00:07:31,957\\nHe\\'s gonna stay with her\\nand she\\'ll be:\\n\\n128\\n00:07:32,233 --> 00:07:34,463\\n\"Hi, I\\'m Julie. Ross picked me.\\n\\n129\\n00:07:34,736 --> 00:07:38,797\\nWe\\'ll get married and have lots\\nof kids and dig up stuff together!\"\\n\\n130\\n00:07:40,475 --> 00:07:43,137\\nNo offense, but that\\nsounds nothing like her.\\n\\n131\\n00:07:46,080 --> 00:07:50,073\\nWhat am I gonna do?\\nThis is like a complete nightmare!\\n\\n132\\n00:07:50,318 --> 00:07:54,448\\nI know. This must be so hard.\\n\"Oh, no! Two women love me!\\n\\n133\\n00:07:55,790 --> 00:07:59,055\\nThey\\'re both gorgeous,\\nmy wallet\\'s too small for my 50s...\\n\\n134\\n00:07:59,260 --> 00:08:01,751\\n...and my diamond shoes are too tight!\"'),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content='247\\n00:15:09,082 --> 00:15:10,242\\nNo! I\\n\\n248\\n00:15:10,483 --> 00:15:13,611\\nOkay, look at the other side.\\nLook at Julie\\'s column.\\n\\n249\\n00:15:14,487 --> 00:15:15,954\\n\"She\\'s not Rachem\"?\\n\\n250\\n00:15:17,423 --> 00:15:18,822\\nWhat the hell\\'s a Rachem?\\n\\n251\\n00:15:19,125 --> 00:15:21,150\\nIs that a stupid paleontology word...\\n\\n252\\n00:15:21,394 --> 00:15:23,726\\n... I wouldn\\'t know,\\nbecause I\\'m just a waitress?\\n\\n253\\n00:15:24,297 --> 00:15:25,787\\nRach, come on!\\n\\n254\\n00:15:28,001 --> 00:15:29,832\\nIt\\'s \"She\\'s not Rachel\"!\\n\\n255\\n00:15:30,103 --> 00:15:31,934\\nShe\\'s not....\\n\\n256\\n00:15:39,913 --> 00:15:41,278\\nMy diary! Brilliant!'),\n",
       " Document(metadata={'source': 'data/subtitles/Friends_2x08.srt'}, page_content=\"145\\n00:08:42,594 --> 00:08:44,425\\nNo, Amish boy.\\n\\n146\\n00:08:46,398 --> 00:08:50,061\\nLet's start with the cons\\nbecause they're more fun.\\n\\n147\\n00:08:50,335 --> 00:08:51,165\\nRachel first.\\n\\n148\\n00:08:52,171 --> 00:08:53,331\\nI don't know.\\n\\n149\\n00:08:53,839 --> 00:08:55,067\\nI mean....\\n\\n150\\n00:08:55,274 --> 00:08:59,802\\nAll right, I guess you can say\\nshe's a little spoiled sometimes.\\n\\n151\\n00:09:00,245 --> 00:09:01,940\\nYou could say that.\\n\\n152\\n00:09:03,816 --> 00:09:07,775\\nI guess, sometimes\\nshe's a little ditzy, you know?\\n\\n153\\n00:09:08,153 --> 00:09:11,088\\nAnd I've seen her be a little\\ntoo into her looks.\\n\\n154\\n00:09:11,757 --> 00:09:13,816\\nAnd Julie and I have\\na lot in common...\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975535f2-73e5-4389-91d4-1b9e2594394d",
   "metadata": {},
   "source": [
    "## **Building an End-to-End RAG Chain**\n",
    "\n",
    "**Step 1: Initialize the Chroma DB Connection**  \n",
    "**Step 2: Create a Retriever Object**   \n",
    "**Step 3: Initialize a Chat Prompt Template**  \n",
    "**Step 4: Initialize a Generator (i.e. Chat Model)**  \n",
    "**Step 5: Initialize a Output Parser**   \n",
    "**Step 6: Define a RAG Chain**  \n",
    "**Step 7: Invoke the Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09718171-f4fe-4886-9c37-e9ba72130758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize the Chroma DB Connection\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize the database connection\n",
    "# If database exist, it will connect with the collection_name and persist_directory\n",
    "# Otherwise a new collection will be created\n",
    "db = Chroma(collection_name=\"vector_database\", \n",
    "            embedding_function=embedding_model, \n",
    "            persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# We can check the already existing values\n",
    "print(len(db.get()[\"ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12a3280-28ef-432f-a76a-53922080bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a Retriever Object \n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c140db-1f33-440c-98c9-21daec76b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Initialize a Chat Prompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Answer the question based on the above context: {question}.\n",
    "Provide a detailed answer.\n",
    "Don’t justify your answers.\n",
    "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0466bc9-8813-45ba-af63-8d58f79d532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize a Generator (i.e. Chat Model)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "289ed96b-977b-46e9-982a-bee809b5081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize a Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eac1d29-fe72-449e-99be-8cf5a05dcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define a RAG Chain\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt_template | chat_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff4f3fd-f29a-4f5f-b3c1-4997db26fa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rachem is not a person, it is a misinterpretation of the name Rachel. The speaker is questioning what the term \"Rachem\" means and if it is a term related to paleontology. They clarify that they wouldn\\'t know because they are just a waitress.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the Chain\n",
    "\n",
    "query = 'Who is Rachem?'\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2109d2d6-a41a-4498-ad16-8d8e9fd198e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rachel is described as being a waitress, while Julie is mentioned to have a lot in common with the speaker as they are both paleontologists.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the Chain\n",
    "\n",
    "query = 'What is there on the List comparing Rachel and Julie?'\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
