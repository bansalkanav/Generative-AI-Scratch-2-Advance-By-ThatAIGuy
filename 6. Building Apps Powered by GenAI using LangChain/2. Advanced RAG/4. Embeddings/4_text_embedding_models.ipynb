{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d233ed9-8279-494a-b519-8f862d7087c4",
   "metadata": {},
   "source": [
    "# **Text Embedding Models**\n",
    "\n",
    "The Embeddings class is a class designed for interfacing with text embedding models. There are lots of embedding model providers (OpenAI, Cohere, Hugging Face, etc) - this class is designed to provide a standard interface for all of them.\n",
    "\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "The base Embeddings class in LangChain provides two methods: one for embedding documents and one for embedding a query. The former takes as input multiple texts, while the latter takes a single text. The reason for having these as two separate methods is that some embedding providers have different embedding methods for documents (to be searched over) vs queries (the search query itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685c54df-e7bf-4123-8bac-360db18cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c5038-fbae-4314-9c1f-45da12a5446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa780ef-e228-4fc3-9fe6-42e23234e746",
   "metadata": {},
   "source": [
    "### **Embed Single Query - `embed_query`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5a384e-4791-450e-81dc-1f3e3c2cd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of embedded vector: 1536\n",
      "[0.005384807424727807, -0.0005522561790177147, 0.03896066510130955, -0.002939867294003909, -0.008987877434176603, 0.021116891679065407, -0.017197068620393528, -0.0017239962310982204, -0.0029712125847749776, -0.010499054468180394, 0.022383905738602872, 0.009245239112047377, 0.004035306125525385, -0.009291432711317806, -0.010023924428684487]\n"
     ]
    }
   ],
   "source": [
    "# Embed single query\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Dimensionality of embedded vector:\", len(embedded_query))\n",
    "\n",
    "print(embedded_query[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b33d1-0546-4409-9f5f-9f42c5eff919",
   "metadata": {},
   "source": [
    "### **Embed list of Texts - `embed_documents`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c9dd7a-ff7f-4dd8-9d43-3fadbdf01569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Embeddings: 5\n",
      "Dimensionality of Embeddings: 1536\n"
     ]
    }
   ],
   "source": [
    "# Embed list of texts\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "                                [\n",
    "                                    \"Hi there!\",\n",
    "                                    \"Oh, hello!\",\n",
    "                                    \"What's your name?\",\n",
    "                                    \"My friends call me World\",\n",
    "                                    \"Hello World!\"\n",
    "                                ]\n",
    ")\n",
    "\n",
    "print(\"Number of Embeddings:\", len(embeddings))\n",
    "\n",
    "print(\"Dimensionality of Embeddings:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272a886-fed3-4e10-a12c-c3d87a759dcf",
   "metadata": {},
   "source": [
    "### **Create Embeddings for Subtitles Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91baca3-d78e-41e7-b66d-3bed23fb0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 2356.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all .srt files\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('data/subtitles_data', glob=\"*.srt\", show_progress=True, loader_cls=TextLoader)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"Number of Documents:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009e7572-8273-472d-a68a-161b165f3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))\n",
    "\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee609559-bf85-4f95-9041-de6ac71b1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:01,435 --> 00:00:04,082\n",
      "This is pretty much\n",
      "what's happened so far.\n",
      "\n",
      "2\n",
      "00:00:04,395 --> 00:0\n"
     ]
    }
   ],
   "source": [
    "# To read 0th document, we can use .page_content\n",
    "\n",
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d11663f-e9f5-4d1d-9a53-e8a713c36874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reading the content of all the .srt files\n",
    "\n",
    "# [srt_file.page_content for srt_file in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9597e1d-f715-4388-b376-7c38196ef22e",
   "metadata": {},
   "source": [
    "**Important Note: Be careful running the following code. It will encounter some `cost`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0bb30b-62ce-4391-bc69-f7dfc5e3835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating embeddings for all the 23 .srt files\n",
    "\n",
    "# embedded_docs = embeddings_model.embed_documents([srt_file.page_content for srt_file in docs])\n",
    "\n",
    "# print(\"Type of variable:\", type(embedded_docs))\n",
    "\n",
    "# print(\"Number of embeddings:\", len(embedded_docs))\n",
    "\n",
    "# print(\"Dimensionality of each embedding:\", len(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b122f79-f9b9-40b9-a591-53c6177efc1d",
   "metadata": {},
   "source": [
    "## **HuggingFace Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eed315d-9166-42b8-85d5-7b1c5f7cd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d313924e-4c8b-42bd-ad95-5f00583e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = embeddings_model.embed_documents([\n",
    "                    \"Hi there!\",\n",
    "                    \"Oh, hello!\",\n",
    "                    \"What's your name?\",\n",
    "                    \"My friends call me World\",\n",
    "                    \"Hello World!\"\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f05c09-1f75-42c3-b2b6-bfc3460db8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of variable: <class 'list'>\n",
      "Number of embeddings: 5\n",
      "Dimensionality of each embedding: 768\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of variable:\", type(embedded_docs))\n",
    "\n",
    "print(\"Number of embeddings:\", len(embedded_docs))\n",
    "\n",
    "print(\"Dimensionality of each embedding:\", len(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c680065-2bda-44d5-b5a2-693aea293367",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "We just learned how to take documents and embed them into vectors.\n",
    "\n",
    "These vectors are stored in memory as a Python list. Whenever we restart the program, these Python lists will flush out.\n",
    "\n",
    "How do we make sure these embeddings persist to some permanent storage?\n",
    "\n",
    "**Important Note: If generating embeddings has cost associated with it, why to generate it every time? Why not store these embeddings in a database during the first execution and use these embeddings from the database from next time onwards for better cost management.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
