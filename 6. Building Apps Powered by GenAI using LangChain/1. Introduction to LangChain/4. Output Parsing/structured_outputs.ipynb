{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4d7160-7657-4a66-8c9e-b06dd18c5139",
   "metadata": {},
   "source": [
    "# **Structured Outputs**\n",
    "\n",
    "For many applications, such as chatbots, models need to respond to users directly in natural language. However, there are scenarios where we need models to output in a structured format. For example, we might want to store the model output in a database and ensure that the output conforms to the database schema. This need motivates the concept of structured output, where models can be instructed to respond with a particular output structure.\n",
    "\n",
    "## **Output Parser**\n",
    "Often we need the output of a LLM in a particular format, for example, you want a python datetime object, or a JSON object. LangChain come with Parse utilities allowing you to easily convert output into precise data types or even your own custom class instance with Pydantic.\n",
    "\n",
    "Output parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data.\n",
    "\n",
    "Parser consists of two key elements:\n",
    "- `get_format_instructions()` method:  A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- `parse()` method: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
    "- (Optional)\"Parse with prompt\": A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to be the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n",
    "\n",
    "Output Parser Types:\n",
    "- CSL Parser\n",
    "- Datetime Parser\n",
    "- JSON Parser\n",
    "- Pydantic Parser\n",
    "etc...\n",
    "\n",
    "**Question: What is Pydantic?**  \n",
    "Pydantic is a library which allows us to define data models, validate the data and type coercion.  \n",
    "Coercion in Pydantic refers to its ability to automatically convert input data into the types specified in the model, as long as the conversion is reasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567d306-c0bd-4c14-ab46-8710bcf1d132",
   "metadata": {},
   "source": [
    "## **Comma Separated List Parser**\n",
    "\n",
    "This output parser can be used when you want to return a list of comma-separated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb66a263-96cc-42d2-9ccb-eecda7950b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb683e6d-7d19-4bcc-92c1-a7993686d999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16ee4e6-2e4b-4d78-82fb-c0c582cb262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# prompt -> generate a list of modules one must study to become data scientist\n",
    "\n",
    "example_input = \"Python, DA, SQL, ML, DL\"\n",
    "\n",
    "print(type(example_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19eb38e-6fc3-48c1-bd6e-c33c3790fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Python', 'DA', 'SQL', 'ML', 'DL']\n"
     ]
    }
   ],
   "source": [
    "example_input = \"Python, DA, SQL, ML, DL\"\n",
    "\n",
    "# using parse() method\n",
    "parsed_output = csv_output_parser.parse(example_input)\n",
    "\n",
    "print(type(parsed_output))\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08efd7-d316-4765-a53e-8a70cf5f98c7",
   "metadata": {},
   "source": [
    "## **Building an AI Powered Chef Assistant using CommaSeparatedListOutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850c78f2-dee3-4547-bf35-e1407e666d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f5242f-1517-4b77-bb01-2507894a6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dish_name'], input_types={}, partial_variables={'output_format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template='You are a helpful AI Chef Assistant. \\n                      Given a dish name by user, you can provide the ingredients to prepare the dish.\\n                      Output Format Instructions:\\n                      {output_format_instructions}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dish_name'], input_types={}, partial_variables={}, template='Give me the list of ingredients for cooking {dish_name}.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "                messages=[\n",
    "                      (\"system\", \"\"\"You are a helpful AI Chef Assistant. \n",
    "                      Given a dish name by user, you can provide the ingredients to prepare the dish.\n",
    "                      Output Format Instructions:\n",
    "                      {output_format_instructions}\"\"\"),\n",
    "                      (\"human\", \"Give me the list of ingredients for cooking {dish_name}.\"),\n",
    "                  ],\n",
    "                partial_variables={\"output_format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653b4ff2-bde5-408b-afd6-14fd804399d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740575108.683549 2549997 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "# Import Google ChatModel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "f = open('keys/.gemini.txt')\n",
    "GOOGLE_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatGoogleGenerativeAI(api_key=GOOGLE_API_KEY, model=\"gemini-2.0-flash-exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a6a423-ae97-4536-a898-ae9322478d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fe8e3d-f2b8-4008-ac02-bc00f6bff39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paneer', 'basmati rice', 'onions', 'tomatoes', 'ginger-garlic paste', 'green chilies', 'mint leaves', 'coriander leaves', 'yogurt', 'biryani masala', 'turmeric powder', 'red chili powder', 'garam masala', 'saffron', 'milk', 'ghee', 'oil', 'salt', 'whole spices (bay leaf', 'cinnamon stick', 'cloves', 'cardamom)']\n"
     ]
    }
   ],
   "source": [
    "raw_input = {\"dish_name\": \"paneer biryani\"}\n",
    "\n",
    "response = chain.invoke(raw_input)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d895f2a1-c08a-4582-b9da-393410cd63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb811-9ecd-46e1-8f10-72571f034c70",
   "metadata": {},
   "source": [
    "## **Building an AI Powered Historical Event Teller using Datetime Parser**\n",
    "\n",
    "This OutputParser can be used to parse LLM output into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072bd02b-c06d-4d05-97b2-f62862e8dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/langchain/output_parsers/__init__.py:34: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain.output_parsers.combining import CombiningOutputParser\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00755d45-e38a-4c09-8412-c12eb4540175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0716-07-02T15:45:40.110435Z, 0495-05-18T00:17:02.037880Z, 1152-11-17T05:11:55.348175Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd3acd4-2cda-4776-a90c-968e87133d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=[(\"system\", \"\"\"You are a knowledgeable AI assistant specialized in providing \n",
    "                            accurate dates and times for historical events. When asked about \n",
    "                            a past event, provide the exact date and time. \n",
    "                            If the exact date is uncertain, mention the most widely accepted \n",
    "                            estimate along with sources or references. \n",
    "\n",
    "                            You generate output while following the below mentioned format.\n",
    "                            Output Format Instructions:\n",
    "                            {output_format_instructions}\"\"\"), \n",
    "              (\"user\", \"\"\"Answer the users question:\n",
    "                          Question:\n",
    "                          {question}\"\"\")],\n",
    "    partial_variables={\"output_format_instructions\": output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69182c25-2ba5-4ad4-9287-41b31011880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947-08-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "chain = chat_template | chat_model | output_parser\n",
    "\n",
    "raw_input = {\"question\": \"What is Indian Independence Day?\"}\n",
    "\n",
    "response = chain.invoke(raw_input)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0520093c-fd7c-4ab0-9c28-bd3aa8a64e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141db7-78c2-4d7d-801c-869fe9b7c553",
   "metadata": {},
   "source": [
    "## **Building an AI Powered Song Recommender using Pydantic Parser**\n",
    "\n",
    "This output parser allows users to specify an arbitrary Pydantic Model and query LLMs for outputs that conform to that schema.\n",
    "\n",
    "Use Pydantic to declare your data model. Pydantic’s BaseModel is like a Python dataclass, but with actual type checking + coercion.\n",
    "\n",
    "You should have some Pydantic knowledge to use it.\n",
    "\n",
    "`pip install pydantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88654381-1109-4e7d-a095-181623aea87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Song(BaseModel):\n",
    "    name: str = Field(description=\"Name of a Song\")\n",
    "    geners: list = Field(description=\"List of Geners\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7617763-9a91-48fb-b34f-89ee49951bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of a Song\", \"title\": \"Name\", \"type\": \"string\"}, \"geners\": {\"description\": \"List of Geners\", \"items\": {}, \"title\": \"Geners\", \"type\": \"array\"}}, \"required\": [\"name\", \"geners\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeae8a81-db61-498a-8a5a-f50af164b3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['singer_name'], input_types={}, partial_variables={'output_format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Name of a Song\", \"title\": \"Name\", \"type\": \"string\"}, \"geners\": {\"description\": \"List of Geners\", \"items\": {}, \"title\": \"Geners\", \"type\": \"array\"}}, \"required\": [\"name\", \"geners\"]}\\n```'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template='You are a helpful AI Song Recommendation Engine.\\n                                        You generate output while following the below mentioned format.\\n                                        Output Format Instructions:\\n                                        {output_format_instructions}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['singer_name'], input_types={}, partial_variables={}, template='What is the most famous song by {singer_name}.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Template\n",
    "chat_template = ChatPromptTemplate(\n",
    "                            messages=[(\"system\", \"\"\"You are a helpful AI Song Recommendation Engine.\n",
    "                                        You generate output while following the below mentioned format.\n",
    "                                        Output Format Instructions:\n",
    "                                        {output_format_instructions}\"\"\"), \n",
    "                                      (\"human\", \"What is the most famous song by {singer_name}.\")],\n",
    "                            partial_variables={\"output_format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39be662-5ddf-449b-8c2a-c6269dcc4971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song(name='Kal Ho Naa Ho', geners=['Bollywood', 'Indian Pop'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_template | chat_model | output_parser\n",
    "\n",
    "raw_input = {\"singer_name\": \"sonu nigam\"}\n",
    "\n",
    "chain.invoke(raw_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14516d5e-9cce-46aa-8c3d-5ba65d12f4ef",
   "metadata": {},
   "source": [
    "## **JSONParser without Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f999b0d3-839b-4b60-ae6a-ebf8390008c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50ef41e-b595-4c77-b36a-227bc21753cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9554aac4-e293-4409-aaf1-54531c6f9354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14972f30-6bd5-4b74-8d8c-fb8251e626d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artist': 'Sonu Nigam',\n",
       " 'famous_song': 'Kal Ho Naa Ho',\n",
       " 'reason': \"This song is one of Sonu Nigam's most popular and critically acclaimed songs. It won numerous awards and is widely recognized for its emotional depth and memorable melody.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without pydantic\n",
    "\n",
    "chain = chat_template | chat_model | output_parser\n",
    "\n",
    "raw_input = {\"singer_name\": \"sonu nigam\", \"output_format_instructions\": output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(raw_input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "694fc967-f317-4ca1-a412-39fcc40530b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821b92b-4ab5-4c72-a994-ab7bfe7eff72",
   "metadata": {},
   "source": [
    "## **JSONParser with Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214dc9a7-e86d-4de9-8bab-53dbb5a7e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of a Song\", \"title\": \"Name\", \"type\": \"string\"}, \"geners\": {\"description\": \"List of Geners\", \"items\": {}, \"title\": \"Geners\", \"type\": \"array\"}}, \"required\": [\"name\", \"geners\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser = JsonOutputParser(pydantic_object=Song)\n",
    "\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c3e7a50-9db7-4941-9c94-da1ac833cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ef84474-2fa0-42b4-88b7-990662dad134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Kal Ho Naa Ho', 'geners': ['Bollywood', 'Indian Pop']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input = {\"singer_name\": \"sonu nigam\", \"output_format_instructions\": output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(raw_input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6193c287-1341-4d08-8482-b9d34b0b2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
