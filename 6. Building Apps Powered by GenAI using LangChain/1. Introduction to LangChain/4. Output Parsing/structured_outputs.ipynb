{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4d7160-7657-4a66-8c9e-b06dd18c5139",
   "metadata": {},
   "source": [
    "# **Structured Outputs**\n",
    "\n",
    "For many applications, such as chatbots, models need to respond to users directly in natural language. However, there are scenarios where we need models to output in a structured format. For example, we might want to store the model output in a database and ensure that the output conforms to the database schema. This need motivates the concept of structured output, where models can be instructed to respond with a particular output structure.\n",
    "\n",
    "## **Output Parser**\n",
    "Often we need the output of a LLM in a particular format, for example, you want a python datetime object, or a JSON object. LangChain come with Parse utilities allowing you to easily convert output into precise data types or even your own custom class instance with Pydantic.\n",
    "\n",
    "Output parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data.\n",
    "\n",
    "Parser consists of two key elements:\n",
    "- `get_format_instructions()` method:  A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- `parse()` method: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
    "- (Optional)\"Parse with prompt\": A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to be the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n",
    "\n",
    "Output Parser Types:\n",
    "- CSV Parser\n",
    "- Datetime Parser\n",
    "- JSON Parser\n",
    "- Pydantic Parser\n",
    "etc...\n",
    "\n",
    "**Question: What is Pydantic?**  \n",
    "Pydantic is a library which allows us to define data models, validate the data and type coercion.  \n",
    "Coercion in Pydantic refers to its ability to automatically convert input data into the types specified in the model, as long as the conversion is reasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567d306-c0bd-4c14-ab46-8710bcf1d132",
   "metadata": {},
   "source": [
    "## **CSV Parser**\n",
    "\n",
    "This output parser can be used when you want to return a list of comma-separated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb66a263-96cc-42d2-9ccb-eecda7950b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb683e6d-7d19-4bcc-92c1-a7993686d999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16ee4e6-2e4b-4d78-82fb-c0c582cb262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# prompt -> generate a list of modules one must study to become data scientist\n",
    "\n",
    "example_input = \"Python, DA, SQL, ML, DL\"\n",
    "\n",
    "print(type(example_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19eb38e-6fc3-48c1-bd6e-c33c3790fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Python', 'DA', 'SQL', 'ML', 'DL']\n"
     ]
    }
   ],
   "source": [
    "example_input = \"Python, DA, SQL, ML, DL\"\n",
    "\n",
    "# using parse() method\n",
    "parsed_output = csv_output_parser.parse(example_input)\n",
    "\n",
    "print(type(parsed_output))\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653b4ff2-bde5-408b-afd6-14fd804399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Read the API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f5242f-1517-4b77-bb01-2507894a6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dish_name'], input_types={}, partial_variables={'output_format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions'], input_types={}, partial_variables={}, template='You are a helpful AI Chef Assistant. \\n                      Given a dish name by user, you can provide the ingredients to prepare the dish.\\n                      Output Format Instructions:\\n                      {output_format_instructions}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dish_name'], input_types={}, partial_variables={}, template='Give me the list of ingredients for cooking {dish_name}.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "                messages=[\n",
    "                      (\"system\", \"\"\"You are a helpful AI Chef Assistant. \n",
    "                      Given a dish name by user, you can provide the ingredients to prepare the dish.\n",
    "                      Output Format Instructions:\n",
    "                      {output_format_instructions}\"\"\"),\n",
    "                      (\"human\", \"Give me the list of ingredients for cooking {dish_name}.\"),\n",
    "                  ],\n",
    "                partial_variables={\"output_format_instructions\": csv_output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a6a423-ae97-4536-a898-ae9322478d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | csv_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fe8e3d-f2b8-4008-ac02-bc00f6bff39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paneer',\n",
       " 'basmati rice',\n",
       " 'onions',\n",
       " 'tomatoes',\n",
       " 'yogurt',\n",
       " 'ginger-garlic paste',\n",
       " 'biryani masala',\n",
       " 'green chilies',\n",
       " 'fresh coriander leaves',\n",
       " 'fresh mint leaves',\n",
       " 'peas',\n",
       " 'ghee or oil',\n",
       " 'salt',\n",
       " 'saffron (optional)',\n",
       " 'water']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {\"dish_name\": \"paneer biryani\"}\n",
    "\n",
    "response = chain.invoke(user_input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d895f2a1-c08a-4582-b9da-393410cd63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb811-9ecd-46e1-8f10-72571f034c70",
   "metadata": {},
   "source": [
    "## **Datetime Parser**\n",
    "\n",
    "This OutputParser can be used to parse LLM output into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072bd02b-c06d-4d05-97b2-f62862e8dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/langchain/output_parsers/__init__.py:34: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain.output_parsers.combining import CombiningOutputParser\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00755d45-e38a-4c09-8412-c12eb4540175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1580-12-03T06:06:09.373772Z, 0350-03-31T16:56:42.509928Z, 0383-04-09T23:44:55.787365Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd3acd4-2cda-4776-a90c-968e87133d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the users question:\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Output Format Instructions:\n",
    "{output_format_instructions}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=template, \n",
    "                                 partial_variables={\"output_format_instructions\": output_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18efe6f-b8d4-4839-b8d0-8cfc01fc3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69182c25-2ba5-4ad4-9287-41b31011880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1947, 8, 15, 0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | chat_model | output_parser\n",
    "\n",
    "user_input = {\"question\": \"What is Indian Independence Day?\"}\n",
    "\n",
    "response = chain.invoke(user_input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0520093c-fd7c-4ab0-9c28-bd3aa8a64e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141db7-78c2-4d7d-801c-869fe9b7c553",
   "metadata": {},
   "source": [
    "## **Pydantic Parser**\n",
    "\n",
    "This output parser allows users to specify an arbitrary Pydantic Model and query LLMs for outputs that conform to that schema.\n",
    "\n",
    "Use Pydantic to declare your data model. Pydanticâ€™s BaseModel is like a Python dataclass, but with actual type checking + coercion.\n",
    "\n",
    "You should have some Pydantic knowledge to use it.\n",
    "\n",
    "`pip install pydantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88654381-1109-4e7d-a095-181623aea87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Song(BaseModel):\n",
    "    name: str = Field(description=\"Name of a Song\")\n",
    "    geners: list = Field(description=\"List of Geners\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7617763-9a91-48fb-b34f-89ee49951bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of a Song\", \"title\": \"Name\", \"type\": \"string\"}, \"geners\": {\"description\": \"List of Geners\", \"items\": {}, \"title\": \"Geners\", \"type\": \"array\"}}, \"required\": [\"name\", \"geners\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeae8a81-db61-498a-8a5a-f50af164b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# System Template\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\"You are a helpful AI Song Recommendation Engine.\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(\"What is the most famous song by {singer_name}. \\n{output_format_instructions}\")\n",
    "\n",
    "# Compile a chat prompt\n",
    "chat_template = ChatPromptTemplate(\n",
    "    messages=[system_prompt_template, human_prompt_template], \n",
    "    partial_variables={\"output_format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe0a8de3-da21-46f5-8a07-a2872d420b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39be662-5ddf-449b-8c2a-c6269dcc4971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song(name='Abhi Mujh Mein Kahin', geners=['Bollywood', 'Romantic'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_template | chat_model | parser\n",
    "\n",
    "user_input = {\"singer_name\": \"sonu nigam\"}\n",
    "\n",
    "chain.invoke(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14516d5e-9cce-46aa-8c3d-5ba65d12f4ef",
   "metadata": {},
   "source": [
    "## **JSONParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f999b0d3-839b-4b60-ae6a-ebf8390008c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50ef41e-b595-4c77-b36a-227bc21753cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214dc9a7-e86d-4de9-8bab-53dbb5a7e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"item_i\": {\"description\": \"Breif description and in how much quantity ith item should be used\", \"title\": \"Item I\", \"type\": \"string\"}}, \"required\": [\"item_i\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    item_i: str = Field(description=\"Breif description and in how much quantity ith item should be used\")\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=QueryResponse)\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c3e7a50-9db7-4941-9c94-da1ac833cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_chain = chain = chat_template | chat_model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ef84474-2fa0-42b4-88b7-990662dad134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Kal Ho Naa Ho', 'geners': ['Bollywood', 'Romantic']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {\"singer_name\": \"sonu nigam\"}\n",
    "\n",
    "response = chain.invoke(user_input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6193c287-1341-4d08-8482-b9d34b0b2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
