{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4d7160-7657-4a66-8c9e-b06dd18c5139",
   "metadata": {},
   "source": [
    "# **Output Parsing**\n",
    "\n",
    "Often we need the output of a LLM in a particular format, for example, you want a python datetime object, or a JSON object. LangChain come with Parse utilities allowing you to easily convert output into precise data types or even your own custom class instance with Pydantic.\n",
    "\n",
    "Output parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data.\n",
    "\n",
    "Parser consists of two key elements:\n",
    "- `get_format_instructions()` method:  A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- `parse()` method: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
    "- (Optional)\"Parse with prompt\": A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to be the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n",
    "\n",
    "Output Parser Types:\n",
    "- CSV Parser\n",
    "- Datetime Parser\n",
    "- JSON Parser\n",
    "- Pydantic Parser\n",
    "etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567d306-c0bd-4c14-ab46-8710bcf1d132",
   "metadata": {},
   "source": [
    "## **CSV Parser**\n",
    "\n",
    "This output parser can be used when you want to return a list of comma-separated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb66a263-96cc-42d2-9ccb-eecda7950b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb683e6d-7d19-4bcc-92c1-a7993686d999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19eb38e-6fc3-48c1-bd6e-c33c3790fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'DA', 'SQL', 'ML', 'DL']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = \"Python, DA, SQL, ML, DL\"\n",
    "\n",
    "# using parse() method\n",
    "csv_output_parser.parse(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653b4ff2-bde5-408b-afd6-14fd804399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Read the API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f5242f-1517-4b77-bb01-2507894a6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dish_name', 'output_format_instructions'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful AI Chef.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dish_name', 'output_format_instructions'], template='Give me the ingredients for cooking {dish_name}. {output_format_instructions}'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI Chef.\"),\n",
    "    (\"human\", \"Give me the ingredients for cooking {dish_name}. {output_format_instructions}\"),\n",
    "])\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a6a423-ae97-4536-a898-ae9322478d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | csv_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fe8e3d-f2b8-4008-ac02-bc00f6bff39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paneer',\n",
       " 'basmati rice',\n",
       " 'yogurt',\n",
       " 'onions',\n",
       " 'tomatoes',\n",
       " 'ginger',\n",
       " 'garlic',\n",
       " 'green chilies',\n",
       " 'spices (such as cumin',\n",
       " 'coriander',\n",
       " 'turmeric',\n",
       " 'garam masala)',\n",
       " 'cilantro',\n",
       " 'mint',\n",
       " 'ghee',\n",
       " 'salt',\n",
       " 'water']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"dish_name\": \"paneer biryani\", \"output_format_instructions\": csv_output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d895f2a1-c08a-4582-b9da-393410cd63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14516d5e-9cce-46aa-8c3d-5ba65d12f4ef",
   "metadata": {},
   "source": [
    "## **JSONParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f999b0d3-839b-4b60-ae6a-ebf8390008c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_output_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3e7a50-9db7-4941-9c94-da1ac833cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_chain = chain = prompt_template | chat_model | json_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef84474-2fa0-42b4-88b7-990662dad134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Main Ingredients': ['Paneer (Indian cottage cheese)',\n",
       "  'Basmati rice',\n",
       "  'Onion',\n",
       "  'Tomato',\n",
       "  'Green chili',\n",
       "  'Ginger',\n",
       "  'Garlic',\n",
       "  'Yogurt',\n",
       "  'Fresh cilantro',\n",
       "  'Mint leaves',\n",
       "  'Spices (such as cumin, coriander, turmeric, garam masala)',\n",
       "  'Oil or ghee',\n",
       "  'Salt'],\n",
       " 'Optional Ingredients': ['Mixed vegetables (like carrots, peas, bell peppers)',\n",
       "  'Cashews',\n",
       "  'Raisins']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"dish_name\": \"paneer biryani\", \"output_format_instructions\": json_output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6193c287-1341-4d08-8482-b9d34b0b2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb811-9ecd-46e1-8f10-72571f034c70",
   "metadata": {},
   "source": [
    "## **Datetime Parser**\n",
    "\n",
    "This OutputParser can be used to parse LLM output into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072bd02b-c06d-4d05-97b2-f62862e8dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00755d45-e38a-4c09-8412-c12eb4540175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0766-08-12T18:44:49.184246Z, 1953-02-26T13:12:24.798157Z, 1621-07-14T00:16:29.137230Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As discussed above, lets experiment with get_format_instructions()\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd3acd4-2cda-4776-a90c-968e87133d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{output_format_instructions}\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18efe6f-b8d4-4839-b8d0-8cfc01fc3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "model = OpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69182c25-2ba5-4ad4-9287-41b31011880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1947, 8, 15, 0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | output_parser\n",
    "\n",
    "input = {\"question\": \"What is Indian Independence Day?\", \"output_format_instructions\": output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(input)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0520093c-fd7c-4ab0-9c28-bd3aa8a64e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141db7-78c2-4d7d-801c-869fe9b7c553",
   "metadata": {},
   "source": [
    "## **Pydantic Parser**\n",
    "\n",
    "This output parser allows users to specify an arbitrary Pydantic Model and query LLMs for outputs that conform to that schema.\n",
    "\n",
    "Use Pydantic to declare your data model. Pydantic’s BaseModel is like a Python dataclass, but with actual type checking + coercion.\n",
    "\n",
    "You should have some Pydantic knowledge to use it.\n",
    "\n",
    "`pip install pydantic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88654381-1109-4e7d-a095-181623aea87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "class Song(BaseModel):\n",
    "    name: str = Field(description=\"Name of a Song\")\n",
    "    geners: list = Field(description=\"List of Geners\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7617763-9a91-48fb-b34f-89ee49951bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"Name of a Song\", \"type\": \"string\"}, \"geners\": {\"title\": \"Geners\", \"description\": \"List of Geners\", \"type\": \"array\", \"items\": {}}}, \"required\": [\"name\", \"geners\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeae8a81-db61-498a-8a5a-f50af164b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# System Template\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\"You are a helpful AI Song Recommendation Engine.\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(\"What is the most famous song by {singer_name}. \\n{output_format_instructions}\")\n",
    "\n",
    "# Compile a chat prompt\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt_template, human_prompt_template]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe0a8de3-da21-46f5-8a07-a2872d420b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b39be662-5ddf-449b-8c2a-c6269dcc4971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song(name='Kal Ho Naa Ho', geners=['Bollywood', 'Romantic'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_template | chat_model | parser\n",
    "\n",
    "input = {\"singer_name\": \"sonu nigam\", \"output_format_instructions\": parser.get_format_instructions()}\n",
    "\n",
    "chain.invoke(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
