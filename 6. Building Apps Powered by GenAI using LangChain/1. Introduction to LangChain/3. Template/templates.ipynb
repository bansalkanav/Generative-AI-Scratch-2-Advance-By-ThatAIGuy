{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97cd4b2-0127-48ea-8237-641c715f88c9",
   "metadata": {},
   "source": [
    "# **Templates**\n",
    "**(PromptTemplate and ChatPromptTemplate)**\n",
    "\n",
    "<img src=\"images/langchain_model_io.jpg\">\n",
    "\n",
    "LangChain Expression Language (LCEL) makes it easy to build complex chains from basic components, and supports out of the box functionality such as streaming, parallelism, and logging. \n",
    "\n",
    "The most basic and common use case is chaining a prompt template and a model together. \n",
    "\n",
    "<img src=\"images/langchain_LCEL.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd999c2-5a6b-49bb-a0d8-902ec9e72623",
   "metadata": {},
   "source": [
    "## **PromptTemplate**\n",
    "\n",
    "Input to a model can be a **string** value or **chat message** list.\n",
    "\n",
    "**Prompt Template**  \n",
    "- Prompt Templates are used to convert raw user input to a better input to the LLM.\n",
    "- Templates allow us to easily configure and modify our input prompts to LLM calls.\n",
    "- A template may include instructions, few-shot examples, and specific context and questions appropriate for a given task.\n",
    "- LangChain provides tooling to create and work with prompt templates.\n",
    "- LangChain strives to create model agnostic templates to make it easy to reuse existing templates across different language models.\n",
    "- Typically, language models expect the prompt to either be a string or else a list of chat messages.\n",
    "\n",
    "\n",
    "Prompt templates are used to convert raw user input to a better input to the LLM or ChatModels.  \n",
    "Templates offer a more systematic approach to passing in variables to prompts for models, instead of using f-string literals or .format() calls. The PromptTemplate converts these into function parameter names that we can pass in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f63bb6-dc92-4a62-bd85-7a61989b9321",
   "metadata": {},
   "source": [
    "### **PromptTemplate and from_template()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e2ef49-861a-4249-be5c-d36d06cdb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Creating a prompt template with input variables\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bb94d5-c45c-4eed-9e74-43cd323cebff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective', 'content']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the input variables\n",
    "\n",
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4357d6-0223-47ad-8d81-666d6f839958",
   "metadata": {},
   "source": [
    "### **PromptTemplate - .format(), .format_messages() and .format_prompt()**\n",
    "\n",
    "Templates offer a more systematic approach to passing in variables to prompts for models, instead of using f-string literals or .format() calls. The PromptTemplate converts these into function parameter names that we can pass in.\n",
    "\n",
    "- .format(): Converts the PromptTemplate to `String`\n",
    "- .format_message(): Converts the PromptTemplate to list of `ChatMessages`\n",
    "- .format_prompt(): Converts the PromptTempate to `StringPromptValue`. `PromptValues` can be converted to both LLM (to string) inputs and ChatModel (to messages) inputs. On this we can apply `to_messages()` or `to_string()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcb0059-7e24-4e0c-bd13-71fc8b6e6697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Tell me a funny joke about chickens.\n"
     ]
    }
   ],
   "source": [
    "# format() returns a string\n",
    "\n",
    "prompt = prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd2d02b-1c5e-4845-97ab-9bcf8acb3e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PromptTemplate' object has no attribute 'format_messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m(adjective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunny\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchickens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PromptTemplate' object has no attribute 'format_messages'"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format_messages(adjective=\"funny\", content=\"chickens\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58a1e07-59f4-4ff2-ab0d-2a87023dc6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "text='Tell me a funny joke about chickens.'\n"
     ]
    }
   ],
   "source": [
    "# format_prompt() returns a string i.e. StingPromptValue\n",
    "# PromptValue can be converted to either Strings or Messages\n",
    "\n",
    "prompt = prompt_template.format_prompt(adjective=\"funny\", content=\"chickens\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aeec0c1-146a-433e-85e4-cb5ce5aa12e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[HumanMessage(content='Tell me a funny joke about chickens.')]\n"
     ]
    }
   ],
   "source": [
    "## We can use StingPromptValue and convert it to List of ChatMessages\n",
    "\n",
    "prompt = prompt_template.format_prompt(adjective=\"funny\", content=\"chickens\").to_messages()\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab60b4-68a8-4c0c-864d-4eff3e7c0c29",
   "metadata": {},
   "source": [
    "## **ChatPromptTemplate**\n",
    "\n",
    "The prompt to chat models/ is a list of chat messages.\n",
    "\n",
    "Each chat message is associated with content, and an additional parameter called role. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba8600-1dbe-4006-8c5e-5ab5ae077c28",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate and from_template()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a736db-8c78-439a-8c94-5d6c2b7b4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(\n",
    "    \"What is {topic}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f7c21c-93ba-4cfb-ba5b-338835325024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85412fc6-a79e-4eb7-a98a-d776930a7837",
   "metadata": {},
   "source": [
    "### **ChatPromptTemplate - .format(), .format_messages() and .format_prompt()**\n",
    "\n",
    "Templates offer a more systematic approach to passing in variables to prompts for models, instead of using f-string literals or .format() calls. The PromptTemplate converts these into function parameter names that we can pass in.\n",
    "\n",
    "- .format(): Converts the PromptTemplate to `String`\n",
    "- .format_message(): Converts the PromptTemplate to list of `ChatMessages`\n",
    "- .format_prompt(): Converts the PromptTempate to `ChatPromptValue`. `PromptValues` can be converted to both LLM (to string) inputs and ChatModel (to messages) inputs. On this we can apply `to_messages()` or `to_string()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a49ce6-dc0d-4ad5-88e7-01315c61d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Human: What is machine learning?\n"
     ]
    }
   ],
   "source": [
    "# format() returns a string\n",
    "\n",
    "prompt = chat_template.format(topic=\"machine learning\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e079d5a5-a54c-4dbe-9e26-329d0c81b515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[HumanMessage(content='What is machine learning?')]\n"
     ]
    }
   ],
   "source": [
    "# fomat_messages() return list of chat messages\n",
    "\n",
    "prompt = chat_template.format_messages(topic=\"machine learning\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e119b0-2261-4d38-a01c-eff90fb2dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "messages=[HumanMessage(content='What is machine learning?')]\n"
     ]
    }
   ],
   "source": [
    "# format_prompt() returns a chat here i.e. ChatPromptValue()\n",
    "# PromptValue can be converted to either Strings or Chat Messages\n",
    "\n",
    "prompt = chat_template.format_prompt(topic=\"machine learning\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c39e2c-2b73-49ad-9c05-fb778f60796b",
   "metadata": {},
   "source": [
    "## **ChatPromptTemplate and from_messages()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "927ffc3f-c3c2-4ef2-9edf-1c7d77bb8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b093e8-2626-49a1-9e5a-69abaaa2e52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI bot. Your name is Bob.\\nHuman: Hello, how are you doing?\\nAI: I'm doing well, thanks!\\nHuman: What is your name?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad1ae895-54ad-4eaa-a80c-149bb54dbecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_messages() returns chat messages \n",
    "\n",
    "chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02998b4b-db2a-4c66-a0b6-6b39c5c5132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_prompt() returns a chat here i.e. ChatPromptValue()\n",
    "\n",
    "chat_template.format_prompt(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f36f2-9f16-4239-9572-a9ca72eec8df",
   "metadata": {},
   "source": [
    "## **Designing ChatPromptTemplate using SystemMessagePromptTemplate, HumanMessagePromptTemplate and AIMessagePromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02925376-d6fb-4055-a254-4d1fb9b9384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "# System Template\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\"You are a helpful AI bot. Your name is {name}.\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(\"Hello, how are you doing?\")\n",
    "\n",
    "# AI Template\n",
    "ai_prompt_template = AIMessagePromptTemplate.from_template(\"I'm doing well, thanks!\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template_input = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "# Compile a chat prompt\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt_template, human_prompt_template, ai_prompt_template, human_prompt_template_input]\n",
    ")\n",
    "\n",
    "chat_template.format_prompt(name=\"Bob\", user_input=\"What is your name?\").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d6a4a-ba99-40a2-9e94-9fc77392f67b",
   "metadata": {},
   "source": [
    "### **In above implementation, we can use HumanMessage and AIMessage as shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a176193c-e70d-4722-885f-acb41c633ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'user_input']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# System Template\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\"You are a helpful AI bot. Your name is {name}.\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt = HumanMessage(content=\"Hello, how are you doing?\")\n",
    "\n",
    "# AI Template\n",
    "ai_prompt = AIMessage(content=\"I'm doing well, thanks!\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "# Compile a chat prompt\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt_template, human_prompt, ai_prompt, human_prompt_template]\n",
    ")\n",
    "\n",
    "print(chat_template.input_variables)\n",
    "\n",
    "chat_template.format_prompt(name=\"Bob\", user_input=\"What is your name?\").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439d488-ec08-4d1d-9ce3-eb5189ab362b",
   "metadata": {},
   "source": [
    "## **MessagesPlaceholder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f338db3d-1070-473b-8b8c-a0159d25c38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'name', 'user_input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful AI bot. Your name is {name}.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# System Template\n",
    "system_prompt_template = SystemMessagePromptTemplate.from_template(\"You are a helpful AI bot. Your name is {name}.\")\n",
    "\n",
    "# Human Template\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "\n",
    "# Compile a chat prompt\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt_template, \n",
    "     MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "     human_prompt_template]\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c595134-abe0-4d09-a6c3-9a421915619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human Message\n",
    "human_prompt = HumanMessage(content=\"Hello, how are you doing?\")\n",
    "\n",
    "# AI Message\n",
    "ai_prompt = AIMessage(content=\"I'm doing well, thanks!\")\n",
    "\n",
    "chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\", chat_history=[human_prompt, ai_prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbc7e0-98a8-47d8-9fd5-39cd10076fbf",
   "metadata": {},
   "source": [
    "## **LCEL**  \n",
    "`PromptTemplate` and `ChatPromptTemplate` implement the Runnable interface, the basic building block of the **LangChain Expression Language (LCEL)**. This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
    "\n",
    "**Using `invoke()`:**  \n",
    "`PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`.  \n",
    "A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`.\n",
    "\n",
    "`PromptValues` can be converted to both LLM (to string) inputs and ChatModel (to messages) inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21c57c5-674a-4f82-a849-28df128e2cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = chat_template.invoke({\"name\": \"Bob\", \n",
    "                              \"user_input\": \"What is your name?\", \n",
    "                              \"chat_history\": [human_prompt, ai_prompt]})\n",
    "\n",
    "print(type(prompt))\n",
    "\n",
    "print()\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "002333c5-0cd0-459f-a2a2-cbc79708301f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System: You are a helpful AI bot. Your name is Bob.\\nHuman: Hello, how are you doing?\\nAI: I'm doing well, thanks!\\nHuman: What is your name?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37b48fd4-0b54-42dc-bfd8-85ec64b96c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
