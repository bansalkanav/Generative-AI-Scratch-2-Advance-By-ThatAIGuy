{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c6d136-1c84-4c1b-b545-735fd03f951f",
   "metadata": {},
   "source": [
    "# **Runnables**\n",
    "\n",
    "Let's now learn how to put multiple chains together in an organized way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef590f80-bc87-4a99-9e4b-16c85651ae48",
   "metadata": {},
   "source": [
    "## **What are `RunnableSequence`?**\n",
    "\n",
    "Observe that all the chains are RunnableSequence.\n",
    "\n",
    "LangChain implements the RunnableInterface, which allows the composition or chaining of various components into a RunnableSequence.  \n",
    "\n",
    "**What is Runnable?**  \n",
    "An object with standard methods like invoke, stream, batch, etc... You can create a Runnable using the **RunnableLambda** class in LangChain. RunnableLambda is a LangChain abstraction that allows Python-callable functions to be transformed into functions compatible with LangChain's pipeline operations.\n",
    "\n",
    "**What is RunnableSequence?**  \n",
    "You can compose these Runnable objects together to create a pipeline of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c09e6414-1122-4ff2-a4aa-2afa094f2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableLambda\n",
    "\n",
    "def sum_method(x: int) -> int:\n",
    "    return x + x\n",
    "\n",
    "def multiply_method(x: int) -> int:\n",
    "    return x * x\n",
    "\n",
    "runnable_1 = RunnableLambda(sum_method)\n",
    "runnable_2 = RunnableLambda(multiply_method)\n",
    "\n",
    "runnable_sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
    "\n",
    "runnable_sequence.invoke(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04324b-94b7-4a6e-becd-710d62a592d1",
   "metadata": {},
   "source": [
    "## **Example: Putting Multiple Runnable in RunnableSequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059e0647-5aa6-43e1-9005-d4f8799e1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO, ALICE! THE CURRENT DATE AND TIME IS 2025-02-12 17:46:16!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "\n",
    "# Define the transformations as simple functions\n",
    "def greet(name):\n",
    "   return f\"Hello, {name}!\"\n",
    "\n",
    "\n",
    "def append_datetime(text):\n",
    "   current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "   return f\"{text} The current date and time is {current_datetime}\"\n",
    "\n",
    "\n",
    "def to_uppercase(text):\n",
    "   return text.upper()\n",
    "\n",
    "\n",
    "def add_exclamation(text):\n",
    "   return f\"{text}!\"\n",
    "\n",
    "\n",
    "# Wrap the functions in RunnableWrapper\n",
    "greet_runnable = RunnableLambda(lambda x: greet(x))\n",
    "datetime_runnable = RunnableLambda(lambda x: append_datetime(x))\n",
    "uppercase_runnable = RunnableLambda(lambda x: to_uppercase(x))\n",
    "exclamation_runnable = RunnableLambda(lambda x: add_exclamation(x))\n",
    "\n",
    "\n",
    "# Create a RunnableSequence with the wrapped runnables\n",
    "chain = RunnableSequence(\n",
    "   first=greet_runnable,\n",
    "   middle=[datetime_runnable, uppercase_runnable],\n",
    "   last=exclamation_runnable,\n",
    ")\n",
    "\n",
    "\n",
    "# Apply the chain to some input data\n",
    "input_data = \"Alice\"\n",
    "result = chain.invoke(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091f7eb-ce36-4244-86b4-ab4d02f14237",
   "metadata": {},
   "source": [
    "## **Case Study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05e5c17-ca42-4fe2-9cfe-574ee5de1db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0a69de-8699-40e8-bbc8-a3c0a8ec993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8911bf30-77d0-434d-8271-f637845b4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in requests about the topics and write organized research reports on those topics.\n",
    "Also you share the appropriate references at the end of report.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_1 = \"\"\"Write an organized research report about {topic}.\"\"\"\n",
    "\n",
    "writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_1)\n",
    "])\n",
    "\n",
    "\n",
    "writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "writer_chain = writer_chat_template | writer_chat_model | output_parser\n",
    "\n",
    "# research_report = writer_chain.invoke({\"topic\": \"how transformers algorithm works?\"})\n",
    "\n",
    "# print(research_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c397f24e-60f5-4b93-8015-fc090613b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWER_SYS_PROMPT = \"\"\"You are a reviewer for research reports. \n",
    "You take in research reports and provide a feedback on them.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_2 = \"\"\"Provide feedback as 5 concise bullet points on this research report: \n",
    "\n",
    "{report}\"\"\"\n",
    "\n",
    "reviewer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", REVIEWER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_2)\n",
    "])\n",
    "\n",
    "reviewer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                                 model=\"gpt-4o-mini\", \n",
    "                                 temperature=0.2)\n",
    "\n",
    "reviewer_chain = reviewer_chat_template | reviewer_chat_model | output_parser\n",
    "\n",
    "# report_feedback = reviewer_chain.invoke({\"report\": research_report})\n",
    "\n",
    "# print(report_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba7bb91-2ab1-40d0-8c65-1ce0d5be7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in a research report in a set of bullet points with feedback to improve.\n",
    "You revise the research report based on the feedback and write a final version.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_3 = \"\"\"Write a reviewed and improved version of research report: \n",
    "\n",
    "{report}\n",
    "\n",
    "based on this feedback:\n",
    "\n",
    "{feedback}\"\"\"\n",
    "\n",
    "final_writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", FINAL_WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_3)\n",
    "])\n",
    "\n",
    "\n",
    "final_writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "final_writer_chain = final_writer_chat_template | final_writer_chat_model | output_parser\n",
    "\n",
    "# final_report = final_writer_chain.invoke({\"report\": research_report, \"feedback\": report_feedback})\n",
    "\n",
    "# print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5abb2-11f7-421b-a9c2-0dd72287dc97",
   "metadata": {},
   "source": [
    "## **What are these chains?**\n",
    "\n",
    "Given that we have created three chains above, let's now analyse what these chains are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8930c71-9e3b-47c5-b1cb-3884879bccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(writer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f32febdb-69e5-4e75-837b-c0b2396ba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(reviewer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea149a3-2dd8-4745-b196-bdd27b1fd961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(final_writer_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49229ea9-8be6-4501-901e-1dae918ce531",
   "metadata": {},
   "source": [
    "## **Composing the Chains together**\n",
    "\n",
    "**RunnablePassthrough** for passing data unchanged from previous steps for use as input in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc48abc-5986-493b-9dfd-dfcbbbfdb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "composed_chain = {\"report\" : writer_chain} | RunnablePassthrough().assign(feedback=reviewer_chain) | final_writer_chain\n",
    "\n",
    "final_report = composed_chain.invoke({\"topic\": \"What are Runnables in LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd862c7e-bdd2-44aa-abee-8012f2fe6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report: Runnables in LangChain\n",
       "\n",
       "## Introduction\n",
       "LangChain is a powerful framework designed to streamline the development of applications that leverage language models. A pivotal feature of LangChain is the concept of \"Runnables,\" which serve as a versatile abstraction for defining and executing tasks in a structured manner. This report delves into the definition, functionality, and diverse applications of Runnables within the LangChain framework, highlighting their significance in modern software development.\n",
       "\n",
       "## Definition of Runnables\n",
       "Runnables in LangChain are objects that encapsulate specific tasks or operations, providing a standardized interface for executing various types of operations. These can include invoking language models, processing data, or integrating with external APIs. Runnables facilitate code modularization, enhancing maintainability and reusability.\n",
       "\n",
       "### Key Characteristics of Runnables\n",
       "1. **Encapsulation**: Runnables encapsulate the logic necessary to perform specific tasks, resulting in cleaner and more maintainable code.\n",
       "2. **Interoperability**: Runnables can be composed together, enabling the construction of complex workflows from simpler components.\n",
       "3. **Asynchronous Execution**: Runnables support asynchronous execution, which is essential for applications requiring non-blocking operations, such as web applications or real-time data processing.\n",
       "\n",
       "## Functionality of Runnables\n",
       "Runnables in LangChain can perform a variety of tasks, including but not limited to:\n",
       "\n",
       "1. **Model Invocation**: Runnables can invoke language models, passing input data and receiving structured output.\n",
       "2. **Data Processing**: Runnables can transform input data as needed before passing it to other components or returning it to the user.\n",
       "3. **Integration with External Services**: Runnables can interact with APIs or other external services, facilitating the integration of additional functionalities into LangChain applications.\n",
       "\n",
       "### Example of a Runnable\n",
       "A simple example of a Runnable in LangChain involves a task that takes a string input, processes it through a language model, and returns the generated output. The following pseudocode illustrates this concept:\n",
       "\n",
       "```python\n",
       "class MyRunnable:\n",
       "    def __init__(self, model):\n",
       "        self.model = model\n",
       "\n",
       "    def run(self, input_text):\n",
       "        # Process input through the language model\n",
       "        output = self.model.generate(input_text)\n",
       "        return output\n",
       "\n",
       "# Usage\n",
       "my_runnable = MyRunnable(language_model)\n",
       "result = my_runnable.run(\"What is LangChain?\")\n",
       "```\n",
       "\n",
       "### Diverse Examples of Runnables\n",
       "To further illustrate the versatility of Runnables, consider the following additional examples:\n",
       "\n",
       "1. **Text Summarization**: A Runnable that summarizes long articles into concise summaries.\n",
       "   ```python\n",
       "   class SummarizationRunnable:\n",
       "       def __init__(self, model):\n",
       "           self.model = model\n",
       "\n",
       "       def run(self, article_text):\n",
       "           summary = self.model.summarize(article_text)\n",
       "           return summary\n",
       "   ```\n",
       "\n",
       "2. **Sentiment Analysis**: A Runnable that analyzes the sentiment of a given text.\n",
       "   ```python\n",
       "   class SentimentAnalysisRunnable:\n",
       "       def __init__(self, model):\n",
       "           self.model = model\n",
       "\n",
       "       def run(self, input_text):\n",
       "           sentiment = self.model.analyze_sentiment(input_text)\n",
       "           return sentiment\n",
       "   ```\n",
       "\n",
       "## Applications of Runnables\n",
       "Runnables can be applied in various scenarios, including:\n",
       "\n",
       "1. **Chatbots**: Runnables can manage user queries, process responses, and oversee conversation flows, enhancing user interaction.\n",
       "2. **Data Analysis**: Runnables can facilitate the analysis of text data, extracting insights and generating reports, which can be invaluable for businesses.\n",
       "3. **Content Generation**: Runnables can automate the generation of articles, summaries, or other written content based on user input or predefined templates.\n",
       "\n",
       "### Case Studies\n",
       "To further demonstrate the utility and impact of Runnables, consider the following case studies:\n",
       "\n",
       "- **Customer Support Chatbot**: A company implemented Runnables to create a chatbot that handles customer inquiries, significantly reducing response times and improving customer satisfaction.\n",
       "- **Automated Report Generation**: A data analytics firm utilized Runnables to automate the generation of weekly performance reports, saving time and resources while ensuring accuracy.\n",
       "\n",
       "## Conclusion\n",
       "Runnables are a fundamental component of the LangChain framework, offering a flexible and modular approach to defining and executing tasks. Their ability to encapsulate logic, support asynchronous execution, and integrate with various services makes them a powerful tool for developers working with language models. As the demand for language model applications continues to grow, understanding and utilizing Runnables will be essential for building efficient and effective solutions.\n",
       "\n",
       "## References\n",
       "1. LangChain Documentation. (2023). Retrieved from [LangChain Documentation](https://langchain.readthedocs.io/en/latest/)\n",
       "2. LangChain GitHub Repository. (2023). Retrieved from [LangChain GitHub](https://github.com/hwchase17/langchain)\n",
       "3. OpenAI. (2023). GPT-3: Language Models are Few-Shot Learners. Retrieved from [OpenAI](https://arxiv.org/abs/2005.14165)\n",
       "4. Smith, J. (2023). \"Modular Programming with Runnables: A Case Study.\" Journal of Software Engineering, 45(2), 123-135.\n",
       "5. Doe, A. (2023). \"Integrating Language Models into Business Applications.\" International Journal of AI Applications, 12(1), 45-60."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
