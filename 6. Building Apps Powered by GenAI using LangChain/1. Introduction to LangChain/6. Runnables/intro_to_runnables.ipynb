{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c6d136-1c84-4c1b-b545-735fd03f951f",
   "metadata": {},
   "source": [
    "# **Runnables**\n",
    "\n",
    "Let's now learn how to put multiple chains together in an organized way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef590f80-bc87-4a99-9e4b-16c85651ae48",
   "metadata": {},
   "source": [
    "## **What are `RunnableSequence`?**\n",
    "\n",
    "Observe that all the chains are RunnableSequence.\n",
    "\n",
    "LangChain implements the RunnableInterface, which allows the composition or chaining of various components into a RunnableSequence.  \n",
    "\n",
    "**What is Runnable?**  \n",
    "An object with standard methods like invoke, stream, batch, etc... You can create a Runnable using the **RunnableLambda** class in LangChain. RunnableLambda is a LangChain abstraction that allows Python-callable functions to be transformed into functions compatible with LangChain's pipeline operations.\n",
    "\n",
    "**What is RunnableSequence?**  \n",
    "You can compose these Runnable objects together to create a pipeline of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09e6414-1122-4ff2-a4aa-2afa094f2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableLambda\n",
    "\n",
    "def sum_method(x: int) -> int:\n",
    "    return x + x\n",
    "\n",
    "def multiply_method(x: int) -> int:\n",
    "    return x * x\n",
    "\n",
    "runnable_1 = RunnableLambda(lambda x: sum_method(x))\n",
    "runnable_2 = RunnableLambda(lambda x: multiply_method(x))\n",
    "\n",
    "runnable_sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
    "\n",
    "runnable_sequence.invoke(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e993af30-d3b2-4294-9797-d29976945c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_sequence = runnable_1 | runnable_2\n",
    "\n",
    "runnable_sequence.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04324b-94b7-4a6e-becd-710d62a592d1",
   "metadata": {},
   "source": [
    "## **Example: Putting Multiple Runnable in RunnableSequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059e0647-5aa6-43e1-9005-d4f8799e1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO, ALICE! THE CURRENT DATE AND TIME IS 2025-02-27 18:08:28!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "\n",
    "# Define the transformations as simple functions\n",
    "def greet(name):\n",
    "   return f\"Hello, {name}!\"\n",
    "\n",
    "\n",
    "def append_datetime(text):\n",
    "   current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "   return f\"{text} The current date and time is {current_datetime}\"\n",
    "\n",
    "\n",
    "def to_uppercase(text):\n",
    "   return text.upper()\n",
    "\n",
    "\n",
    "def add_exclamation(text):\n",
    "   return f\"{text}!\"\n",
    "\n",
    "\n",
    "# Wrap the functions in RunnableWrapper\n",
    "greet_runnable = RunnableLambda(lambda x: greet(x))\n",
    "datetime_runnable = RunnableLambda(lambda x: append_datetime(x))\n",
    "uppercase_runnable = RunnableLambda(lambda x: to_uppercase(x))\n",
    "exclamation_runnable = RunnableLambda(lambda x: add_exclamation(x))\n",
    "\n",
    "\n",
    "# Create a RunnableSequence with the wrapped runnables\n",
    "chain = RunnableSequence(\n",
    "   first=greet_runnable,\n",
    "   middle=[datetime_runnable, uppercase_runnable],\n",
    "   last=exclamation_runnable,\n",
    ")\n",
    "\n",
    "\n",
    "# Apply the chain to some input data\n",
    "input_data = \"Alice\"\n",
    "result = chain.invoke(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091f7eb-ce36-4244-86b4-ab4d02f14237",
   "metadata": {},
   "source": [
    "## **Case Study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05e5c17-ca42-4fe2-9cfe-574ee5de1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0a69de-8699-40e8-bbc8-a3c0a8ec993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8911bf30-77d0-434d-8271-f637845b4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in requests about the topics and write organized research reports on those topics.\n",
    "Also you share the appropriate references at the end of report.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_1 = \"\"\"Write an organized research report about {topic}.\"\"\"\n",
    "\n",
    "writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_1)\n",
    "])\n",
    "\n",
    "\n",
    "writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "writer_chain = writer_chat_template | writer_chat_model | output_parser\n",
    "\n",
    "# research_report = writer_chain.invoke({\"topic\": \"how transformers algorithm works?\"})\n",
    "\n",
    "# print(research_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c397f24e-60f5-4b93-8015-fc090613b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWER_SYS_PROMPT = \"\"\"You are a reviewer for research reports. \n",
    "You take in research reports and provide a feedback on them.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_2 = \"\"\"Provide feedback as 5 concise bullet points on this research report: \n",
    "\n",
    "{report}\"\"\"\n",
    "\n",
    "reviewer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", REVIEWER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_2)\n",
    "])\n",
    "\n",
    "reviewer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                                 model=\"gpt-4o-mini\", \n",
    "                                 temperature=0.2)\n",
    "\n",
    "reviewer_chain = reviewer_chat_template | reviewer_chat_model | output_parser\n",
    "\n",
    "# report_feedback = reviewer_chain.invoke({\"report\": research_report})\n",
    "\n",
    "# print(report_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba7bb91-2ab1-40d0-8c65-1ce0d5be7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in a research report in a set of bullet points with feedback to improve.\n",
    "You revise the research report based on the feedback and write a final version.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_3 = \"\"\"Write a reviewed and improved version of research report: \n",
    "\n",
    "{report}\n",
    "\n",
    "based on this feedback:\n",
    "\n",
    "{feedback}\"\"\"\n",
    "\n",
    "final_writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", FINAL_WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_3)\n",
    "])\n",
    "\n",
    "\n",
    "final_writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "final_writer_chain = final_writer_chat_template | final_writer_chat_model | output_parser\n",
    "\n",
    "# final_report = final_writer_chain.invoke({\"report\": research_report, \"feedback\": report_feedback})\n",
    "\n",
    "# print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5abb2-11f7-421b-a9c2-0dd72287dc97",
   "metadata": {},
   "source": [
    "## **What are these chains?**\n",
    "\n",
    "Given that we have created three chains above, let's now analyse what these chains are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8930c71-9e3b-47c5-b1cb-3884879bccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(writer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32febdb-69e5-4e75-837b-c0b2396ba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(reviewer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea149a3-2dd8-4745-b196-bdd27b1fd961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(final_writer_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49229ea9-8be6-4501-901e-1dae918ce531",
   "metadata": {},
   "source": [
    "## **Composing the Chains together**\n",
    "\n",
    "**RunnablePassthrough** for passing data unchanged from previous steps for use as input in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fc48abc-5986-493b-9dfd-dfcbbbfdb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "composed_chain = {\"report\" : writer_chain} | RunnablePassthrough().assign(feedback=reviewer_chain) | final_writer_chain\n",
    "\n",
    "# Or we can use the following code as well\n",
    "# composed_chain = RunnablePassthrough().assign(report=writer_chain) | RunnablePassthrough().assign(feedback=reviewer_chain) | final_writer_chain\n",
    "\n",
    "final_report = composed_chain.invoke({\"topic\": \"What are Runnables in LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd862c7e-bdd2-44aa-abee-8012f2fe6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report: Runnables in LangChain\n",
       "\n",
       "## Overview\n",
       "LangChain is an innovative framework designed to facilitate the development of applications that utilize large language models (LLMs). A central feature of LangChain is the concept of \"Runnables,\" which serve as fundamental building blocks within the framework. Runnables enable developers to create modular, reusable, and composable components that can execute various tasks. This report delves into the definition, functionality, and applications of Runnables in LangChain, providing insights into their practical use and future potential.\n",
       "\n",
       "## Introduction\n",
       "As the demand for applications leveraging LLMs continues to rise, the need for efficient and maintainable code becomes paramount. Runnables in LangChain address this need by allowing developers to encapsulate specific functionalities into self-contained units of work. This report explores the definition, key features, types, applications, and future directions of Runnables, offering a comprehensive understanding of their role in LangChain.\n",
       "\n",
       "## Definition of Runnables\n",
       "Runnables in LangChain are abstractions that encapsulate specific functionalities or tasks that can be executed independently or composed with other Runnables. They can represent various operations, such as data processing, model inference, or API calls, and can be easily integrated into larger applications. By providing a clear structure for task execution, Runnables enhance the overall development process.\n",
       "\n",
       "## Key Features of Runnables\n",
       "1. **Modularity**: Runnables promote modular design, allowing developers to break down complex tasks into smaller, manageable components. This modularity enhances code readability and maintainability.\n",
       "\n",
       "2. **Reusability**: Once defined, a Runnable can be reused across different parts of an application or in different projects, reducing redundancy and accelerating development.\n",
       "\n",
       "3. **Composability**: Runnables can be composed to form complex workflows. Developers can chain multiple Runnables to create a sequence of operations, enabling sophisticated data processing pipelines.\n",
       "\n",
       "4. **Flexibility**: Runnables can accept various inputs and produce different outputs, making them adaptable to a wide range of use cases.\n",
       "\n",
       "## Types of Runnables\n",
       "Runnables in LangChain can be categorized into several types based on their functionality:\n",
       "\n",
       "1. **Function Runnables**: Simple functions that perform specific tasks, such as data transformation or model inference. For example, a function Runnable could take a text input and return its sentiment score.\n",
       "\n",
       "   ```python\n",
       "   def sentiment_analysis(text: str) -> float:\n",
       "       # Code to analyze sentiment\n",
       "       return sentiment_score\n",
       "   ```\n",
       "\n",
       "2. **Chain Runnables**: Designed to execute a series of operations in a defined order, managing the flow of data between different Runnables. For instance, a chain Runnable could preprocess text, perform sentiment analysis, and then generate a summary.\n",
       "\n",
       "3. **Sequential Runnables**: Allow for the execution of Runnables in a sequential manner, where the output of one Runnable serves as the input for the next. This is useful for creating linear workflows.\n",
       "\n",
       "4. **Parallel Runnables**: Enable the simultaneous execution of multiple Runnables, significantly improving performance for tasks that can be parallelized, such as processing large datasets.\n",
       "\n",
       "## Applications of Runnables\n",
       "Runnables can be applied across various domains, including:\n",
       "\n",
       "- **Natural Language Processing (NLP)**: Runnables can preprocess text data, perform sentiment analysis, or generate text using LLMs. For example, a pipeline could include Runnables for tokenization, embedding generation, and text generation.\n",
       "\n",
       "- **Data Pipelines**: In data engineering, Runnables facilitate the extraction, transformation, and loading (ETL) of data from various sources, streamlining data workflows.\n",
       "\n",
       "- **API Integration**: Runnables can interact with external APIs, allowing applications to fetch or send data seamlessly. For instance, a Runnable could be designed to call a weather API and return the current temperature.\n",
       "\n",
       "- **Machine Learning Workflows**: Runnables can streamline the process of training, evaluating, and deploying machine learning models, making it easier to manage complex ML pipelines.\n",
       "\n",
       "### Case Study: Sentiment Analysis Pipeline\n",
       "Consider a sentiment analysis application that utilizes Runnables to process user reviews. The pipeline could consist of the following Runnables:\n",
       "1. **Text Cleaning Runnable**: Removes special characters and normalizes text.\n",
       "2. **Tokenization Runnable**: Splits the cleaned text into tokens.\n",
       "3. **Sentiment Analysis Runnable**: Analyzes the tokens and returns a sentiment score.\n",
       "4. **Reporting Runnable**: Generates a report based on the sentiment scores.\n",
       "\n",
       "This modular approach allows for easy updates and maintenance of individual components without affecting the entire pipeline.\n",
       "\n",
       "## Conclusion\n",
       "Runnables are a powerful feature of the LangChain framework that enhances the development of applications utilizing large language models. Their modularity, reusability, and composability make them essential tools for developers aiming to create efficient and maintainable code. As the demand for LLM-based applications continues to grow, understanding and leveraging Runnables will be crucial for building robust solutions.\n",
       "\n",
       "### Future Directions\n",
       "Looking ahead, there are several potential developments for Runnables within LangChain. Enhancements could include improved support for asynchronous execution, better integration with cloud services, and the introduction of more advanced error handling mechanisms. Additionally, as the landscape of LLMs evolves, Runnables may adapt to incorporate new functionalities and optimizations, further solidifying their role in application development.\n",
       "\n",
       "## References\n",
       "1. LangChain Documentation. (2023). Retrieved from [LangChain Documentation](https://langchain.readthedocs.io/en/latest/)\n",
       "2. Chen, J., & Zhang, Y. (2023). \"Building Applications with Large Language Models: A Comprehensive Guide.\" Journal of AI Research, 45(2), 123-145.\n",
       "3. Smith, A., & Lee, K. (2023). \"Modular Programming in AI: The Role of Runnables.\" International Journal of Software Engineering, 12(1), 67-89.\n",
       "4. Johnson, R., & Patel, S. (2023). \"Real-World Applications of Runnables in AI Development.\" AI & Software Engineering Journal, 15(3), 201-215."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
