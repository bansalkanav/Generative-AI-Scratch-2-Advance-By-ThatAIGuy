{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c6d136-1c84-4c1b-b545-735fd03f951f",
   "metadata": {},
   "source": [
    "# **Runnables**\n",
    "\n",
    "Let's now learn how to put multiple chains together in an organized way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef590f80-bc87-4a99-9e4b-16c85651ae48",
   "metadata": {},
   "source": [
    "## **What are `RunnableSequence`?**\n",
    "\n",
    "Observe that all the chains are RunnableSequence.\n",
    "\n",
    "LangChain implements the RunnableInterface, which allows the composition or chaining of various components into a RunnableSequence.  \n",
    "\n",
    "**What is Runnable?**  \n",
    "An object with standard methods like invoke, stream, batch, etc... You can create a Runnable using the **RunnableLambda** class in LangChain. RunnableLambda is a LangChain abstraction that allows Python-callable functions to be transformed into functions compatible with LangChain's pipeline operations.\n",
    "\n",
    "**What is RunnableSequence?**  \n",
    "You can compose these Runnable objects together to create a pipeline of operations.\n",
    "\n",
    "**What is RunnableParallel?**  \n",
    "Runnable that runs a mapping of Runnables in parallel, and returns a mapping of their outputs.\n",
    "\n",
    "RunnableParallel is one of the two main composition primitives for the LCEL, alongside RunnableSequence. It invokes Runnables concurrently, providing the same input to each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09e6414-1122-4ff2-a4aa-2afa094f2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence, RunnableParallel\n",
    "\n",
    "def sum_method(x: int) -> int:\n",
    "    return x + x\n",
    "\n",
    "def multiply_method(x: int) -> int:\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7942b9b4-e0a5-4c2d-8a11-216ffeb62654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting methods to Runnables\n",
    "\n",
    "runnable_1 = RunnableLambda(lambda x: sum_method(x))\n",
    "runnable_2 = RunnableLambda(lambda x: multiply_method(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2021a71a-3824-42c7-9e9d-18994f4f26ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a Runnable Sequence\n",
    "\n",
    "runnable_sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
    "\n",
    "runnable_sequence.invoke(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e993af30-d3b2-4294-9797-d29976945c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to define Runnable Sequence\n",
    "\n",
    "runnable_sequence = runnable_1 | runnable_2\n",
    "\n",
    "runnable_sequence.invoke(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cd946a-2471-4c99-9f51-c401e539eee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum_out': 4, 'mult_out': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a Runnable Parallel\n",
    "\n",
    "runnable_parallel = RunnableParallel(sum_out=runnable_1, mult_out=runnable_2)\n",
    "\n",
    "runnable_parallel.invoke(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865190d8-a318-44d0-ac4a-2351bc9a6dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum_out': 6, 'mult_out': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to define Runnable Parallel\n",
    "\n",
    "runnable_parallel = RunnableParallel({'sum_out': runnable_1, 'mult_out': runnable_2})\n",
    "\n",
    "runnable_parallel.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04324b-94b7-4a6e-becd-710d62a592d1",
   "metadata": {},
   "source": [
    "## **Example: Putting Multiple Runnable in RunnableSequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059e0647-5aa6-43e1-9005-d4f8799e1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO, ALICE! THE CURRENT DATE AND TIME IS 2025-02-28 15:59:43!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "\n",
    "# Define the transformations as simple functions\n",
    "def greet(name):\n",
    "   return f\"Hello, {name}!\"\n",
    "\n",
    "\n",
    "def append_datetime(text):\n",
    "   current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "   return f\"{text} The current date and time is {current_datetime}\"\n",
    "\n",
    "\n",
    "def to_uppercase(text):\n",
    "   return text.upper()\n",
    "\n",
    "\n",
    "def add_exclamation(text):\n",
    "   return f\"{text}!\"\n",
    "\n",
    "\n",
    "# Wrap the functions in RunnableWrapper\n",
    "greet_runnable = RunnableLambda(lambda x: greet(x))\n",
    "datetime_runnable = RunnableLambda(lambda x: append_datetime(x))\n",
    "uppercase_runnable = RunnableLambda(lambda x: to_uppercase(x))\n",
    "exclamation_runnable = RunnableLambda(lambda x: add_exclamation(x))\n",
    "\n",
    "\n",
    "# Create a RunnableSequence with the wrapped runnables\n",
    "chain = RunnableSequence(\n",
    "   first=greet_runnable,\n",
    "   middle=[datetime_runnable, uppercase_runnable],\n",
    "   last=exclamation_runnable,\n",
    ")\n",
    "\n",
    "\n",
    "# Apply the chain to some input data\n",
    "input_data = \"Alice\"\n",
    "result = chain.invoke(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58be5920-3965-477f-80b5-7b331f04ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO, ALICE! THE CURRENT DATE AND TIME IS 2025-02-28 15:59:47!\n"
     ]
    }
   ],
   "source": [
    "# Create a RunnableSequence with the wrapped runnables\n",
    "chain = greet_runnable | datetime_runnable | uppercase_runnable | exclamation_runnable\n",
    "\n",
    "# Apply the chain to some input data\n",
    "input_data = \"Alice\"\n",
    "result = chain.invoke(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03fd43-8f42-4cad-8908-85f9a080f9f1",
   "metadata": {},
   "source": [
    "## **RunnablePassThrough**\n",
    "\n",
    "Runnable to passthrough inputs either:\n",
    "- unchanged (or)\n",
    "-  with additional keys - with the help of assign method.\n",
    "\n",
    "This Runnable behaves almost like the identity function, except that it can be configured to add additional keys to the output, if the input is a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2a6917-8ba5-4598-b518-8670871862c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'origin': 1, 'modified': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x+1\n",
    ")\n",
    "\n",
    "runnable.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b33e552-bebf-4cf6-b07b-5964165ad5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified Example\n",
    "\n",
    "runnable = {\"original\": RunnablePassthrough()} | RunnableLambda(lambda x: x[\"original\"]+1)\n",
    "\n",
    "runnable.invoke(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81112c96-9e66-4500-9bd0-e62718a544c1",
   "metadata": {},
   "source": [
    "**Important:**  \n",
    "In some cases, it may be useful to pass the input through while adding some keys to the output. In this case, you can use the assign method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c456be6-c967-482d-913d-1906b8ec7e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm1': 'completion', 'llm2': 'completion', 'total_chars': 20}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return \"completion\"\n",
    "\n",
    "runnable = {\n",
    "    'llm1':  fake_llm,\n",
    "    'llm2':  fake_llm,\n",
    "} | RunnablePassthrough.assign(\n",
    "    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\n",
    ")\n",
    "\n",
    "runnable.invoke('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d091f7eb-ce36-4244-86b4-ab4d02f14237",
   "metadata": {},
   "source": [
    "## **Case Study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e05e5c17-ca42-4fe2-9cfe-574ee5de1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0a69de-8699-40e8-bbc8-a3c0a8ec993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8911bf30-77d0-434d-8271-f637845b4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in requests about the topics and write organized research reports on those topics.\n",
    "Also you share the appropriate references at the end of report.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_1 = \"\"\"Write an organized research report about {topic}.\"\"\"\n",
    "\n",
    "writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_1)\n",
    "])\n",
    "\n",
    "\n",
    "writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "writer_chain = writer_chat_template | writer_chat_model | output_parser\n",
    "\n",
    "# research_report = writer_chain.invoke({\"topic\": \"how transformers algorithm works?\"})\n",
    "\n",
    "# print(research_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c397f24e-60f5-4b93-8015-fc090613b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWER_SYS_PROMPT = \"\"\"You are a reviewer for research reports. \n",
    "You take in research reports and provide a feedback on them.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_2 = \"\"\"Provide feedback as 5 concise bullet points on this research report: \n",
    "\n",
    "{report}\"\"\"\n",
    "\n",
    "reviewer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", REVIEWER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_2)\n",
    "])\n",
    "\n",
    "reviewer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                                 model=\"gpt-4o-mini\", \n",
    "                                 temperature=0.2)\n",
    "\n",
    "reviewer_chain = reviewer_chat_template | reviewer_chat_model | output_parser\n",
    "\n",
    "# report_feedback = reviewer_chain.invoke({\"report\": research_report})\n",
    "\n",
    "# print(report_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba7bb91-2ab1-40d0-8c65-1ce0d5be7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_WRITER_SYS_PROMPT = \"\"\"You are a research assistant and scientific writer.\n",
    "You take in a research report in a set of bullet points with feedback to improve.\n",
    "You revise the research report based on the feedback and write a final version.\"\"\"\n",
    "\n",
    "HUMAN_PROMPT_3 = \"\"\"Write a reviewed and improved version of research report: \n",
    "\n",
    "{report}\n",
    "\n",
    "based on this feedback:\n",
    "\n",
    "{feedback}\"\"\"\n",
    "\n",
    "final_writer_chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", FINAL_WRITER_SYS_PROMPT), \n",
    "    (\"human\", HUMAN_PROMPT_3)\n",
    "])\n",
    "\n",
    "\n",
    "final_writer_chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                               model=\"gpt-4o-mini\",\n",
    "                               temperature=0.0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "final_writer_chain = final_writer_chat_template | final_writer_chat_model | output_parser\n",
    "\n",
    "# final_report = final_writer_chain.invoke({\"report\": research_report, \"feedback\": report_feedback})\n",
    "\n",
    "# print(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5abb2-11f7-421b-a9c2-0dd72287dc97",
   "metadata": {},
   "source": [
    "## **What are these chains?**\n",
    "\n",
    "Given that we have created three chains above, let's now analyse what these chains are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8930c71-9e3b-47c5-b1cb-3884879bccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(writer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f32febdb-69e5-4e75-837b-c0b2396ba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(reviewer_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea149a3-2dd8-4745-b196-bdd27b1fd961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "print(type(final_writer_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49229ea9-8be6-4501-901e-1dae918ce531",
   "metadata": {},
   "source": [
    "## **Composing the Chains together**\n",
    "\n",
    "**RunnablePassthrough** for passing data unchanged from previous steps for use as input in later steps.\n",
    "\n",
    "<img src=\"images/composing_chains.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc48abc-5986-493b-9dfd-dfcbbbfdb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "composed_chain = {\"report\" : writer_chain} | RunnablePassthrough().assign(feedback=reviewer_chain) | final_writer_chain\n",
    "\n",
    "final_report = composed_chain.invoke({\"topic\": \"What are Runnables in LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "299ba292-bda5-4635-9469-28c1d19b2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can use the following code as well\n",
    "# composed_chain = RunnablePassthrough().assign(report=writer_chain) | RunnablePassthrough().assign(feedback=reviewer_chain) | final_writer_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd862c7e-bdd2-44aa-abee-8012f2fe6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Research Report: Runnables in LangChain\n",
       "\n",
       "## Introduction\n",
       "LangChain is an innovative framework designed to facilitate the development of applications that utilize language models. A key component of LangChain is the concept of \"Runnables,\" which serve as fundamental building blocks within the framework. Runnables enable developers to create modular and reusable components that can execute various tasks related to language processing. This report provides a comprehensive overview of Runnables in LangChain, including their definition, functionality, use cases, advantages, and future directions.\n",
       "\n",
       "## Definition of Runnables\n",
       "Runnables in LangChain are abstractions that encapsulate specific tasks or operations that can be executed independently or in conjunction with other Runnables. Each Runnable is a self-contained unit of work that can take inputs, perform computations or transformations, and produce outputs. This modular approach allows developers to build complex workflows by chaining together multiple Runnables, enhancing the overall efficiency and organization of the application.\n",
       "\n",
       "## Functionality of Runnables\n",
       "Runnables in LangChain are designed to be flexible and versatile, supporting a variety of tasks, including but not limited to:\n",
       "\n",
       "1. **Text Generation**: Runnables can invoke language models to generate text based on given prompts. For example, a Runnable could be created to generate a summary of a document by passing the document text as input to a language model.\n",
       "   \n",
       "   ```python\n",
       "   from langchain import Runnable\n",
       "   from langchain.llms import OpenAI\n",
       "\n",
       "   text_generator = Runnable(OpenAI(model=\"text-davinci-003\"))\n",
       "   summary = text_generator.run(\"Summarize the following text: [insert text here]\")\n",
       "   ```\n",
       "\n",
       "2. **Data Transformation**: Runnables can process and transform data, such as cleaning or formatting text. For instance, a Runnable could be implemented to remove special characters from a dataset.\n",
       "\n",
       "3. **API Calls**: Runnables can be used to make API requests to external services, integrating additional functionalities into the application. For example, a Runnable could fetch data from a weather API and format it for user display.\n",
       "\n",
       "4. **Conditional Logic**: Developers can implement conditional logic within Runnables to control the flow of execution based on specific criteria, allowing for dynamic responses in applications.\n",
       "\n",
       "## Use Cases\n",
       "Runnables can be employed in various scenarios, including:\n",
       "\n",
       "1. **Chatbots**: Runnables can handle user inputs, generate responses, and manage conversation flows. For example, a chatbot could use Runnables to process user queries and provide relevant answers.\n",
       "\n",
       "2. **Data Pipelines**: In data processing applications, Runnables can be chained together to create a pipeline that ingests, processes, and outputs data. This is particularly useful in ETL (Extract, Transform, Load) processes.\n",
       "\n",
       "3. **Content Creation**: Runnables can automate the generation of articles, summaries, or reports based on user-defined parameters, streamlining content production.\n",
       "\n",
       "4. **Interactive Applications**: Runnables can facilitate interactive applications that require real-time processing and feedback, such as educational tools or gaming applications.\n",
       "\n",
       "## Advantages of Runnables\n",
       "The use of Runnables in LangChain offers several advantages:\n",
       "\n",
       "1. **Modularity**: Runnables promote a modular design, allowing developers to create reusable components that can be easily integrated into different applications.\n",
       "\n",
       "2. **Scalability**: The ability to chain Runnables together enables the development of scalable applications that can handle complex workflows efficiently.\n",
       "\n",
       "3. **Maintainability**: By encapsulating specific tasks within Runnables, the codebase becomes easier to maintain and update, reducing technical debt.\n",
       "\n",
       "4. **Flexibility**: Runnables can be easily modified or replaced without affecting the overall application, providing flexibility in development.\n",
       "\n",
       "## Comparative Analysis\n",
       "When compared to similar concepts in other frameworks, Runnables in LangChain stand out due to their emphasis on modularity and ease of integration. For instance, while other frameworks may offer monolithic components, Runnables allow for granular control over individual tasks, making it easier to adapt and extend applications. This modular approach not only enhances reusability but also simplifies debugging and testing processes.\n",
       "\n",
       "## Future Directions\n",
       "As LangChain continues to evolve, there are several potential developments for Runnables that could enhance their functionality:\n",
       "\n",
       "1. **Enhanced Error Handling**: Future versions could introduce more robust error handling mechanisms within Runnables, allowing for better fault tolerance in complex workflows.\n",
       "\n",
       "2. **Integration with Emerging Technologies**: Runnables could be expanded to integrate with emerging technologies such as real-time data streams or advanced machine learning models, broadening their applicability.\n",
       "\n",
       "3. **User-Friendly Interfaces**: Developing graphical interfaces for creating and managing Runnables could make the framework more accessible to non-technical users, fostering wider adoption.\n",
       "\n",
       "4. **Community Contributions**: Encouraging community contributions to the library of Runnables could lead to a richer ecosystem of pre-built components, accelerating development for users.\n",
       "\n",
       "## Conclusion\n",
       "Runnables are a core feature of the LangChain framework, providing a powerful mechanism for building modular and reusable components in language model applications. Their versatility allows developers to create a wide range of applications, from chatbots to data processing pipelines. By leveraging Runnables, developers can enhance the scalability, maintainability, and flexibility of their projects, paving the way for innovative solutions in the realm of language processing.\n",
       "\n",
       "## References\n",
       "1. LangChain Documentation. (2023). Retrieved from [LangChain Documentation](https://langchain.readthedocs.io/en/latest/)\n",
       "2. LangChain GitHub Repository. (2023). Retrieved from [LangChain GitHub](https://github.com/hwchase17/langchain)\n",
       "3. Research Papers on Language Models and Frameworks. (2023). Various authors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
