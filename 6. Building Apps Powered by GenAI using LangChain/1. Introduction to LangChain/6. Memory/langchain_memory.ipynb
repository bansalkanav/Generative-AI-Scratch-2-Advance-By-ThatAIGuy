{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5c86a2-76b6-4cf7-8f94-051684e7784d",
   "metadata": {},
   "source": [
    "# **LangChain Memory**\n",
    "\n",
    "Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation. At bare minimum, a conversational system should be able to access some window of past messages directly. A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships.\n",
    "\n",
    "We call this ability to store information about past interactions \"memory\". LangChain provides a lot of utilities for adding memory to a system. These utilities can be used by themselves or incorporated seamlessly into a chain.\n",
    "\n",
    "## **Building memory into a system**\n",
    "The two core design decisions in any memory system are:\n",
    "- How state is stored\n",
    "- How state is queried\n",
    "\n",
    "## **What's covered?**\n",
    "- ConversationBufferMemory\n",
    "- End-to-end Example: Conversational AI Bot\n",
    "- Saving and Loading a Chat History\n",
    "- ChatMessageHistory [Beta]\n",
    "- ConversationBufferWindowMemory [Beta]\n",
    "- ConversationSummaryMemory [Beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1113868-bbd5-4d29-a118-7591b61fa8ff",
   "metadata": {},
   "source": [
    "## **ConversationBufferMemory**\n",
    "\n",
    "Let's take a look at how to use ConversationBufferMemory in chains. ConversationBufferMemory is an extremely simple form of memory that just keeps a list of chat messages in a buffer and passes those into the prompt template.\n",
    "\n",
    "This memory type can be connected to a conversation. It allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f451bf-b4c1-4f49-afb5-125a09115327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Set up an instance of Conversation buffer memory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0173b80b-ffa0-4763-bec7-613d4c3c3544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Memory\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe06229-eeda-4386-ae9d-529750380e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading memory buffer with history\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df5ae9-8f27-4b80-b69b-6d9190252629",
   "metadata": {},
   "source": [
    "### **Renaming the memory variable and Adding Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165114b6-e0a0-4937-accd-5bf95d0921b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2f436c-121c-44a7-94a3-65894bddeea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fc894a-7112-412d-acac-5dd20f90d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: hi!\\nAI: what's up?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27dad62-cc81-48bc-aec2-2f32286d73eb",
   "metadata": {},
   "source": [
    "### **By default, memory is returned as a single string. In order to return as a list of messages, you can set `return_messages=True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64315d88-e7bd-4936-b037-8e94ba227aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13ee9e6-4563-4d88-ac57-08ff96c54c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi!'),\n",
       "  AIMessage(content=\"what's up?\")]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf6c5b9-ff8e-4082-9fd7-e1aeba5f49ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210d13f-efab-42cd-bfa9-3d04865048bb",
   "metadata": {},
   "source": [
    "## **End-to-end Example: Conversational AI Bot**\n",
    "\n",
    "<img src=\"images/memory.png\">\n",
    "\n",
    "### **Steps:**\n",
    "1. Import Chat Model and Configure the API Key\n",
    "2. Create Chat Template\n",
    "3. Initialize the Memory\n",
    "4. Create a Output Parser\n",
    "5. Build a Chain\n",
    "6. Invoke the chain with human_input and chat_history\n",
    "7. Saving to memory\n",
    "8. Run Step 6 and 7 in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d0c98f-d4c6-4a53-89f1-11c67009d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Import Chat Model and Configure the API Key\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f452f6-4d40-406e-99fa-414807724238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Create Chat Template\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # The persistent system prompt\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # Creating a chat_history placeholder\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  \n",
    "        # Human Prompt\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298a7a3c-7e07-4e55-b2bf-66241285b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Initialize the Memory\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824d4ee4-f149-437e-82d5-cc1604e697fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ff4467-cefe-4dac-9abe-aa1a5dcd86f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a chatbot having a conversation with a human.'), HumanMessage(content='Hi')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template.invoke({\"human_input\": \"Hi\", \"chat_history\": memory.buffer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306c003b-b708-4abe-9fb4-db825ce3d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Create a Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87955a78-0f81-45df-a31a-37a82396f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Build a Chain\n",
    "\n",
    "chain = chat_prompt_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c207e06b-8612-4807-a2c1-105f8606dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How are you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 - Invoke the chain with human_input and chat_history\n",
    "\n",
    "human_input = \"Hi\"\n",
    "\n",
    "response = chain.invoke({\"human_input\": human_input, \"chat_history\": memory.buffer})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8d5156-4ef1-47a1-8d51-707e498957e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b812329f-26b6-4e7a-afec-40189215a390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi'), AIMessage(content='Hello! How are you today?')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7 - Saving to Memory\n",
    "\n",
    "memory.chat_memory.add_user_message(human_input)\n",
    "memory.chat_memory.add_ai_message(response)\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb90ceb4-329f-429a-ace5-3893261c45a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  I am good. My name is Kanav.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: I am good. My name is Kanav.\n",
      "*AI: Nice to meet you, Kanav! Is there anything specific you'd like to talk about or do today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  Can you tell me what kind of tasks can you solve for me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: Can you tell me what kind of tasks can you solve for me?\n",
      "*AI: I can assist you with a variety of tasks such as answering questions, providing information on a wide range of topics, helping you make decisions, offering suggestions, giving advice, and even just chatting for fun. Feel free to ask me anything you'd like help with!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  That's good to know.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: That's good to know.\n",
      "*AI: I'm here to help whenever you need assistance or just want to chat. Is there anything else you'd like to know or talk about?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  What is my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: What is my name?\n",
      "*AI: Your name is Kanav.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: bye\n"
     ]
    }
   ],
   "source": [
    "# Step 8 - Run Step 6 and 7 in a loop\n",
    "\n",
    "while True:\n",
    "    human_input = input('Enter your input: ')\n",
    "    print(f\"*User: {human_input}\")\n",
    "    if human_input in ['bye', 'quit', 'exit']:\n",
    "        break\n",
    "    response = chain.invoke({\"human_input\": human_input, \"chat_history\": memory.buffer})\n",
    "    print(f\"*AI: {response}\")\n",
    "\n",
    "    memory.chat_memory.add_user_message(human_input)\n",
    "    memory.chat_memory.add_ai_message(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fd022-9da2-4d0b-9581-cf8363f36097",
   "metadata": {},
   "source": [
    "## **Saving a Chat History**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f57c5-b8f5-4efc-a409-bf4e221629d4",
   "metadata": {},
   "source": [
    "**Let's now learn to save this history on the disk so that whenever we can load the history whenever we chat with our assistant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8217df9c-fcd3-4f4d-baa2-85e413e7e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "chat_history = pickle.dumps(memory)\n",
    "\n",
    "with open(\"chats_data/conversation_memory.pkl\", \"wb\") as f:\n",
    "    f.write(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5c8b1-4521-43ce-83f2-f1c84d3609d0",
   "metadata": {},
   "source": [
    "## **Loading a Chat History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ca65b7-c292-45f2-92e4-20f84679277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hi'), AIMessage(content='Hello! How are you today?'), HumanMessage(content='I am good. My name is Kanav.'), AIMessage(content=\"Nice to meet you, Kanav! Is there anything specific you'd like to talk about or do today?\"), HumanMessage(content='Can you tell me what kind of tasks can you solve for me?'), AIMessage(content=\"I can assist you with a variety of tasks such as answering questions, providing information on a wide range of topics, helping you make decisions, offering suggestions, giving advice, and even just chatting for fun. Feel free to ask me anything you'd like help with!\"), HumanMessage(content=\"That's good to know.\"), AIMessage(content=\"I'm here to help whenever you need assistance or just want to chat. Is there anything else you'd like to know or talk about?\"), HumanMessage(content='What is my name?'), AIMessage(content='Your name is Kanav.')]) return_messages=True memory_key='chat_history'\n"
     ]
    }
   ],
   "source": [
    "chat_history_loaded = pickle.load(open(\"chats_data/conversation_memory.pkl\", \"rb\"))\n",
    "\n",
    "print(chat_history_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35fb23db-84d4-45cf-82a9-1e46184fba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi'),\n",
       " AIMessage(content='Hello! How are you today?'),\n",
       " HumanMessage(content='I am good. My name is Kanav.'),\n",
       " AIMessage(content=\"Nice to meet you, Kanav! Is there anything specific you'd like to talk about or do today?\"),\n",
       " HumanMessage(content='Can you tell me what kind of tasks can you solve for me?'),\n",
       " AIMessage(content=\"I can assist you with a variety of tasks such as answering questions, providing information on a wide range of topics, helping you make decisions, offering suggestions, giving advice, and even just chatting for fun. Feel free to ask me anything you'd like help with!\"),\n",
       " HumanMessage(content=\"That's good to know.\"),\n",
       " AIMessage(content=\"I'm here to help whenever you need assistance or just want to chat. Is there anything else you'd like to know or talk about?\"),\n",
       " HumanMessage(content='What is my name?'),\n",
       " AIMessage(content='Your name is Kanav.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_loaded.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80fdea-b9c7-4b6d-84a6-354df7fa4273",
   "metadata": {},
   "source": [
    "## **ChatMessageHistory**\n",
    "\n",
    "This allows us to mannualy add the messages to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c2193d3-ed97-469d-91c6-3d6ce38b255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f937b886-4df3-437f-8138-5d77582322cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello, Nice to meet you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17d20acb-d312-4bdc-9fdd-c5a027e1eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(\"Nice to meet you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9530da13-8741-4d78-9660-f429b2b40af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, Nice to meet you.'),\n",
       " AIMessage(content='Nice to meet you!')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e27849-a745-4de1-8dc9-6e5e0aa07b0a",
   "metadata": {},
   "source": [
    "## **ConversationBufferWindowMemory [Beta]**\n",
    "\n",
    "With this we will have an ability to call back just a window of conversation.\n",
    "\n",
    "`ConversationBufferWindowMemory` keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1b54d98-0e59-4814-a056-3e642add1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a463341-8d6c-499a-8e89-1f00ea172b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Set up an instance of Conversation buffer window memory\n",
    "window_memory = ConversationBufferWindowMemory(k=1)\n",
    "# here, k most recent interactions will be refered to answer the user queries\n",
    "\n",
    "# Set up an assistant\n",
    "conversation = ConversationChain(llm=chat_model, memory=window_memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e3eb121-e9ce-47c9-bf4e-f0890eff7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, How are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a6f9c7-9877-4114-a8e4-792c739c6db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, How are you?\n",
      "AI: Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\n",
      "Human: What is the new thing you learned recently?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I recently learned about a new algorithm for image recognition that improves accuracy by 10%. It's called Convolutional Neural Networks with Attention Mechanism (CNN-AM). This algorithm focuses on specific parts of an image to make more accurate predictions. I found it fascinating how it can significantly improve image recognition tasks.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is the new thing you learned recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6957c84a-f049-486b-8357-7e942285d36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the new thing you learned recently?\n",
      "AI: I recently learned about a new algorithm for image recognition that improves accuracy by 10%. It's called Convolutional Neural Networks with Attention Mechanism (CNN-AM). This algorithm focuses on specific parts of an image to make more accurate predictions. I found it fascinating how it can significantly improve image recognition tasks.\n",
      "Human: Sounds interesting. Can you teach it to me in a simple term?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! In simple terms, the CNN-AM algorithm is like a detective that pays extra attention to important parts of a picture to figure out what the picture is showing. It helps computers recognize images more accurately by focusing on key details.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Sounds interesting. Can you teach it to me in a simple term?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72908c73-13cc-4e00-a47d-f39165b390f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hello, How are you?'), AIMessage(content=\"Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\"), HumanMessage(content='What is the new thing you learned recently?'), AIMessage(content=\"I recently learned about a new algorithm for image recognition that improves accuracy by 10%. It's called Convolutional Neural Networks with Attention Mechanism (CNN-AM). This algorithm focuses on specific parts of an image to make more accurate predictions. I found it fascinating how it can significantly improve image recognition tasks.\"), HumanMessage(content='Sounds interesting. Can you teach it to me in a simple term?'), AIMessage(content='Sure! In simple terms, the CNN-AM algorithm is like a detective that pays extra attention to important parts of a picture to figure out what the picture is showing. It helps computers recognize images more accurately by focusing on key details.')]) k=1\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d247501-b4c9-4217-9625-52a9013bc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Sounds interesting. Can you teach it to me in a simple term?\n",
      "AI: Sure! In simple terms, the CNN-AM algorithm is like a detective that pays extra attention to important parts of a picture to figure out what the picture is showing. It helps computers recognize images more accurately by focusing on key details.\n"
     ]
    }
   ],
   "source": [
    "print(window_memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e96e65-92d9-4586-9e87-2a867905de1a",
   "metadata": {},
   "source": [
    "## **ConversationSummaryBufferMemory [Beta]**\n",
    "\n",
    "It allows us to call a LLM for a summary of all the historical conversation.\n",
    "\n",
    "`ConversationSummaryBufferMemory` combines the two ideas. It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both. It uses token length rather than number of interactions to determine when to flush interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84384898-a0e2-47bd-a657-5a6e04f8afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=chat_model, max_token_limit=100)\n",
    "\n",
    "conversation = ConversationChain(llm=chat_model, memory=summary_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28737e5c-ead4-4d73-96ad-3ad24b40e764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! For your upcoming Data Science interview, I recommend starting with the basics of Python programming. Here's a suggested study plan:\\n\\n1. Week 1: Introduction to Python - Learn about Python syntax, data types, variables, and basic operations.\\n2. Week 2: Control flow and functions - Dive into if statements, loops, and functions in Python.\\n3. Week 3: Data structures - Explore lists, dictionaries, tuples, and sets in Python.\\n4. Week 4: File handling and modules - Understand how to read and write files, as well as import modules in Python.\\n5. Week 5: Object-oriented programming - Learn about classes, objects, and inheritance in Python.\\n6. Week 6: Libraries and frameworks - Familiarize yourself with popular libraries like NumPy, Pandas, and Matplotlib for data manipulation and visualization.\\n7. Week 7: Practice coding exercises - Solve coding challenges on platforms like LeetCode or HackerRank to reinforce your skills.\\n8. Week 8: Review and mock interviews - Review key concepts and participate in mock interviews to prepare for your Data Science interview.\\n\\nRemember to practice regularly and apply what you've learned to real-world projects. Good luck with your interview preparation! Let me know if you have any other questions.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Give me a study plan for Python Programming for my upcoming Data Science Interview.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf2997a5-a9ba-48e3-8fb6-19cdd0a5fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For Machine Learning, I recommend a 12-week study plan to cover the fundamentals of machine learning algorithms, data preprocessing, model evaluation, feature selection, and tuning hyperparameters. I also suggest diving into specific topics such as regression, classification, clustering, and neural networks. Additionally, it's important to work on real-world projects and participate in Kaggle competitions to apply your knowledge and showcase your skills to potential employers during the interview process. Let me know if you need more specific details or resources for your study plan!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Also share for Machine Learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f1ed8b0-782b-420c-8725-77d1beb5df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(summary_memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3711d1f2-ee16-412a-a694-c9d687e7fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000024EA67AC2B0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024EA67AF7C0>, openai_api_key=SecretStr('**********'), openai_proxy='') max_token_limit=100 moving_summary_buffer='The human asks the AI for study plans for Python Programming and Machine Learning for an upcoming Data Science Interview. The AI provides a detailed 8-week study plan for Python and a 12-week study plan for Machine Learning, emphasizing the importance of regular practice, real-world application, and participating in Kaggle competitions to showcase skills.'\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
