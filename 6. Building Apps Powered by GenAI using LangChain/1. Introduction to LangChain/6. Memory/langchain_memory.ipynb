{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5c86a2-76b6-4cf7-8f94-051684e7784d",
   "metadata": {},
   "source": [
    "# **LangChain Memory**\n",
    "\n",
    "Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation. At bare minimum, a conversational system should be able to access some window of past messages directly. A more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships.\n",
    "\n",
    "We call this ability to store information about past interactions \"memory\". LangChain provides a lot of utilities for adding memory to a system. These utilities can be used by themselves or incorporated seamlessly into a chain.\n",
    "\n",
    "## **Building memory into a system**\n",
    "The two core design decisions in any memory system are:\n",
    "- How state is stored\n",
    "- How state is queried\n",
    "\n",
    "## **What's covered?**\n",
    "- ConversationBufferMemory\n",
    "- End-to-end Example: Conversational AI Bot\n",
    "- Saving and Loading a Chat History\n",
    "- ChatMessageHistory [Beta]\n",
    "- ConversationBufferWindowMemory [Beta]\n",
    "- ConversationSummaryMemory [Beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1113868-bbd5-4d29-a118-7591b61fa8ff",
   "metadata": {},
   "source": [
    "## **ConversationBufferMemory**\n",
    "\n",
    "Let's take a look at how to use ConversationBufferMemory in chains. ConversationBufferMemory is an extremely simple form of memory that just keeps a list of chat messages in a buffer and passes those into the prompt template.\n",
    "\n",
    "This memory type can be connected to a conversation. It allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f451bf-b4c1-4f49-afb5-125a09115327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Set up an instance of Conversation buffer memory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0173b80b-ffa0-4763-bec7-613d4c3c3544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Memory\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe06229-eeda-4386-ae9d-529750380e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading memory buffer with history\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df5ae9-8f27-4b80-b69b-6d9190252629",
   "metadata": {},
   "source": [
    "### **Renaming the memory variable and Adding Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165114b6-e0a0-4937-accd-5bf95d0921b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2f436c-121c-44a7-94a3-65894bddeea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: hi!\\nAI: what's up?\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fc894a-7112-412d-acac-5dd20f90d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: hi!\\nAI: what's up?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27dad62-cc81-48bc-aec2-2f32286d73eb",
   "metadata": {},
   "source": [
    "### **By default, memory is returned as a single string. In order to return as a list of messages, you can set `return_messages=True`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64315d88-e7bd-4936-b037-8e94ba227aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13ee9e6-4563-4d88-ac57-08ff96c54c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi!'),\n",
       "  AIMessage(content=\"what's up?\")]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf6c5b9-ff8e-4082-9fd7-e1aeba5f49ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210d13f-efab-42cd-bfa9-3d04865048bb",
   "metadata": {},
   "source": [
    "## **End-to-end Example: Conversational AI Bot**\n",
    "\n",
    "<img src=\"images/memory.png\">\n",
    "\n",
    "### **Steps:**\n",
    "1. Import Chat Model and Configure the API Key\n",
    "2. Create Chat Template\n",
    "3. Initialize the Memory\n",
    "4. Create a Output Parser\n",
    "5. Build a Chain\n",
    "6. Invoke the chain with human_input and chat_history\n",
    "7. Saving to memory\n",
    "8. Run Step 6 and 7 in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c109071-82b9-4628-a1eb-a0fcfe7588bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Import Chat Model and Configure the API Key\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup API Key\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "OPENAI_API_KEY = f.read()\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d991c8dd-ddb9-47b0-b483-ede46666e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Create Chat Template\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # The persistent system prompt\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # Creating a chat_history placeholder\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  \n",
    "        # Human Prompt\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70898aed-44e4-49cf-bd30-bf6832f4abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Initialize the Memory\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5795c6-04cc-42dd-a874-29a2ab0fc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Create a Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d6c9f-caff-42db-8cda-1d51864ad344",
   "metadata": {},
   "source": [
    "#### **RunnablePassthrough:** RunnablePassthrough on its own allows you to pass inputs unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd49c94-8ce5-432f-923b-292de7d84c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Build a Chain (Another way)\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Define a function to load the message from memory\n",
    "def get_messages_from_memory(human_input):\n",
    "    return memory.load_memory_variables(human_input)['chat_history']\n",
    "\n",
    "# Define a chain\n",
    "chain = RunnablePassthrough.assign(\n",
    "            chat_history=RunnableLambda(get_messages_from_memory)\n",
    "        ) | chat_prompt_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dce5bc2-84d8-4c46-b8ac-48a2e82040f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 - Invoke the chain with human_input and chat_history\n",
    "\n",
    "query = {\"human_input\": \"Hi, How are you?\"}\n",
    "\n",
    "response = chain.invoke(query)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8058b89e-e632-44b1-b291-918f9e90f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f4b47a-9190-4f3d-82b6-d1b0f585a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, How are you?'),\n",
       " AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\")]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7 - Saving to memory\n",
    "\n",
    "memory.save_context(query, {\"output\" : response})\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de61677b-9f1f-4e23-a100-eb279342f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  *User:   My name is Kanav. Can you tell me what kind of tasks can you solve for me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: *User:   My name is Kanav. Can you tell me what kind of tasks can you solve for me?\n",
      "*AI: Hello Kanav! I can help answer questions, provide information, offer suggestions, assist with problem-solving, and engage in conversation on a variety of topics. Feel free to ask me anything you'd like help with!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  That's good to know.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: That's good to know.\n",
      "*AI: I'm glad you think so! If you have any questions or need assistance with anything, feel free to ask. I'm here to help!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  What is my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: What is my name?\n",
      "*AI: Your name is Kanav.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your input:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*User: bye\n"
     ]
    }
   ],
   "source": [
    "# Step 8 - Run Step 6 and 7 in a loop\n",
    "\n",
    "while True:\n",
    "    query = {\"human_input\" : input('Enter your input: ')}\n",
    "    print(f\"*User: {query['human_input']}\")\n",
    "    if query[\"human_input\"] in ['bye', 'quit', 'exit']:\n",
    "        break\n",
    "    response = chain.invoke(query)\n",
    "    print(f\"*AI: {response}\")\n",
    "\n",
    "    memory.save_context(query, {\"output\" : response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc450acb-d899-4180-9a39-e480de710128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi, How are you?'),\n",
       "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
       "  HumanMessage(content='*User:   My name is Kanav. Can you tell me what kind of tasks can you solve for me?'),\n",
       "  AIMessage(content=\"Hello Kanav! I can help answer questions, provide information, offer suggestions, assist with problem-solving, and engage in conversation on a variety of topics. Feel free to ask me anything you'd like help with!\"),\n",
       "  HumanMessage(content=\"That's good to know.\"),\n",
       "  AIMessage(content=\"I'm glad you think so! If you have any questions or need assistance with anything, feel free to ask. I'm here to help!\"),\n",
       "  HumanMessage(content='What is my name?'),\n",
       "  AIMessage(content='Your name is Kanav.')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fd022-9da2-4d0b-9581-cf8363f36097",
   "metadata": {},
   "source": [
    "## **Saving a Chat History**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f57c5-b8f5-4efc-a409-bf4e221629d4",
   "metadata": {},
   "source": [
    "**Let's now learn to save this history on the disk so that whenever we can load the history whenever we chat with our assistant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8217df9c-fcd3-4f4d-baa2-85e413e7e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "chat_history = pickle.dumps(memory)\n",
    "\n",
    "with open(\"chats_data/conversation_memory.pkl\", \"wb\") as f:\n",
    "    f.write(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5c8b1-4521-43ce-83f2-f1c84d3609d0",
   "metadata": {},
   "source": [
    "## **Loading a Chat History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ca65b7-c292-45f2-92e4-20f84679277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, How are you?'), AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"), HumanMessage(content='*User:   My name is Kanav. Can you tell me what kind of tasks can you solve for me?'), AIMessage(content=\"Hello Kanav! I can help answer questions, provide information, offer suggestions, assist with problem-solving, and engage in conversation on a variety of topics. Feel free to ask me anything you'd like help with!\"), HumanMessage(content=\"That's good to know.\"), AIMessage(content=\"I'm glad you think so! If you have any questions or need assistance with anything, feel free to ask. I'm here to help!\"), HumanMessage(content='What is my name?'), AIMessage(content='Your name is Kanav.')]) return_messages=True memory_key='chat_history'\n"
     ]
    }
   ],
   "source": [
    "chat_history_loaded = pickle.load(open(\"chats_data/conversation_memory.pkl\", \"rb\"))\n",
    "\n",
    "print(chat_history_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35fb23db-84d4-45cf-82a9-1e46184fba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi, How are you?'),\n",
       "  AIMessage(content=\"Hello! I'm just a chatbot, so I don't have feelings, but I'm here to help you. How can I assist you today?\"),\n",
       "  HumanMessage(content='*User:   My name is Kanav. Can you tell me what kind of tasks can you solve for me?'),\n",
       "  AIMessage(content=\"Hello Kanav! I can help answer questions, provide information, offer suggestions, assist with problem-solving, and engage in conversation on a variety of topics. Feel free to ask me anything you'd like help with!\"),\n",
       "  HumanMessage(content=\"That's good to know.\"),\n",
       "  AIMessage(content=\"I'm glad you think so! If you have any questions or need assistance with anything, feel free to ask. I'm here to help!\"),\n",
       "  HumanMessage(content='What is my name?'),\n",
       "  AIMessage(content='Your name is Kanav.')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_loaded.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e27849-a745-4de1-8dc9-6e5e0aa07b0a",
   "metadata": {},
   "source": [
    "## **ConversationBufferWindowMemory [Beta]**\n",
    "\n",
    "With this we will have an ability to call back just a window of conversation.\n",
    "\n",
    "`ConversationBufferWindowMemory` keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1b54d98-0e59-4814-a056-3e642add1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f6cfa4-4295-4bb9-a27b-ff1eecabf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # The persistent system prompt\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # Creating a chat_history placeholder\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  \n",
    "        # Human Prompt\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a463341-8d6c-499a-8e89-1f00ea172b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Set up an instance of Conversation buffer window memory\n",
    "window_memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=2)\n",
    "# here, k most recent interactions will be refered to answer the user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e245412-48d5-4b24-bd19-400cd53b7081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33873757-7f54-4efa-99bb-de43ab875dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Define a function to load the message from memory\n",
    "def get_messages_from_memory(human_input):\n",
    "    return window_memory.load_memory_variables(human_input)['chat_history']\n",
    "\n",
    "# Define a chain\n",
    "chain = RunnablePassthrough.assign(\n",
    "            chat_history=RunnableLambda(get_messages_from_memory)\n",
    "        ) | chat_prompt_template | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1bacfb-039d-4f2d-a1e1-b7e03d8c549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 most populous states in India are Uttar Pradesh, Maharashtra, and Bihar.\n"
     ]
    }
   ],
   "source": [
    "query = {\"human_input\" : \"What are the top 3 states of India on the basis of population?\"}\n",
    "\n",
    "response = chain.invoke(query)\n",
    "\n",
    "window_memory.save_context(query, {\"output\" : response.content})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7984cf91-e75b-49e0-b531-b3b2aa96c23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What are the top 3 states of India on the basis of population?'),\n",
       "  AIMessage(content='The top 3 most populous states in India are Uttar Pradesh, Maharashtra, and Bihar.')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f276e7-8ec1-42c6-915e-fb51f8d4a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next two most populous states in India are West Bengal and Madhya Pradesh.\n"
     ]
    }
   ],
   "source": [
    "query = {\"human_input\" : \"What are the next 2 states?\"}\n",
    "\n",
    "response = chain.invoke(query)\n",
    "\n",
    "window_memory.save_context(query, {\"output\" : response.content})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d247501-b4c9-4217-9625-52a9013bc39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What are the top 3 states of India on the basis of population?'),\n",
       "  AIMessage(content='The top 3 most populous states in India are Uttar Pradesh, Maharashtra, and Bihar.'),\n",
       "  HumanMessage(content='What are the next 2 states?'),\n",
       "  AIMessage(content='The next two most populous states in India are West Bengal and Madhya Pradesh.')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57196c-f3b8-49d3-b812-8c4d999e6adf",
   "metadata": {},
   "source": [
    "## **ChatMessageHistory**\n",
    "\n",
    "`ChatMessageHistory` allows us to store separate conversation histories per user or session which is often done by the real-time chatbots. `session_id` is used to distinguish between separate conversations.\n",
    "\n",
    "In order to use it, we can use a `get_session_history` function which take `session_id` and returns a message history object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73fcc4a9-2e7a-4f83-bc25-4c95d573ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5043c4-3fa1-484f-beae-937766b8741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_store = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf48d3a-ddb1-4dce-ae51-5e243960d184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f366aa0-12c2-48f9-a551-b4d716c78563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859bfc7-8290-467a-8502-bba089f942c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
