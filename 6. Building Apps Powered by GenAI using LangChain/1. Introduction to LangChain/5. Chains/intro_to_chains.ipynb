{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6184a554-1851-4a31-abf1-87c2561f29be",
   "metadata": {},
   "source": [
    "# **Chains**\n",
    "\n",
    "Chains allows us to link the output of one LLM call as the input of another call.\n",
    "\n",
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa15d575-4524-41b8-a4a1-f3da57950631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3e157e-dd82-4541-925e-70a640a3723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069c2668-961a-43ba-a5ee-ff85b0297cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot who expertise in Data Science Tutor. You are known to make any complex topic simpler even for a beginner.\"),\n",
    "        (\"human\", \"What is {topic}?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb84660-ae5b-485c-b2f7-b6dbd9788b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9b77b3-15b6-4969-81db-ca93e76d7476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feature selection is the process of selecting a subset of relevant features or variables from a larger set of features in a dataset that are most important for predicting the target variable. The goal of feature selection is to improve the performance of the machine learning model by reducing overfitting, increasing computational efficiency, and enhancing interpretability.\\n\\nThere are several techniques for feature selection, including filter methods, wrapper methods, and embedded methods. Filter methods rank features based on statistical measures like correlation or mutual information with the target variable. Wrapper methods use a specific machine learning algorithm to evaluate different subsets of features. Embedded methods select features as part of the model building process, such as regularization techniques like Lasso or Ridge regression.\\n\\nOverall, feature selection plays a crucial role in building accurate and efficient machine learning models by focusing on the most relevant features while ignoring irrelevant or redundant ones.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_template | chat_model | output_parser\n",
    "\n",
    "input = {\"topic\": \"Feature Selection\"}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684de3e-ab75-4792-b353-c2fcd18bb890",
   "metadata": {},
   "source": [
    "### **More on chains coming soon....**\n",
    "\n",
    "## **LLMChain (Legacy)**\n",
    "\n",
    "## **SimpleSequentialChain (Legacy)**\n",
    "\n",
    "Now that we understood how to use LLMChain object, we can chain them together to create more complex functionality with LangChain.\n",
    "\n",
    "Let's now understand this with the following example:\n",
    "1. Take an input topic from the user\n",
    "2. Using the user input generate an outline for a blog\n",
    "3. Using the blog outline generate the technical blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d094ae5-50da-49a4-b3e9-389244181bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61418f6f-9ae7-4368-b997-c222774f85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc73e90d-daec-4432-bb12-85b2245dede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the user input generate an outline for a blog\n",
    "\n",
    "chat_template_one = ChatPromptTemplate.from_template(\n",
    "    \"Given me a simple bullet point outline for a blog post on {topic}.\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=chat_model, prompt=chat_template_one, output_key=\"outline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585b9363-35ea-4edd-80d3-104062388f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the blog outline generate the technical blog post\n",
    "\n",
    "chat_template_two = ChatPromptTemplate.from_template(\n",
    "    \"Write a technical blog post using this outline {outline}.\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=chat_model, prompt=chat_template_two, output_key=\"blog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9960971a-a8b7-4326-88e1-768786fab49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "full_chain = SequentialChain(chains=[chain_one, chain_two], \n",
    "                             input_variables=['topic'], \n",
    "                             output_variables=['outline', 'blog'], \n",
    "                             verbose=True)\n",
    "\n",
    "input = {\"topic\": \"One hot encoding\"}\n",
    "\n",
    "result = full_chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e67b76e7-e7b2-4029-87a5-1c6189e449ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'One hot encoding',\n",
       " 'outline': '- Introduction to one hot encoding\\n- Explanation of what one hot encoding is and why it is used in machine learning\\n- Steps involved in one hot encoding\\n- Example of one hot encoding in action\\n- Advantages and disadvantages of one hot encoding\\n- Conclusion and final thoughts on the importance of one hot encoding in data preprocessing.',\n",
       " 'blog': 'Introduction to One Hot Encoding\\n\\nIn the world of machine learning and data preprocessing, one hot encoding is a commonly used technique to convert categorical data into numerical data. This process is important because machine learning algorithms typically work with numerical data, and converting categorical data into numerical form allows these algorithms to better understand and process the data.\\n\\nExplanation of One Hot Encoding and its Importance in Machine Learning\\n\\nOne hot encoding is a technique where categorical variables are converted into a binary matrix representation. Each category is represented as a binary vector where only one element is hot (1) and all others are cold (0). This allows machine learning algorithms to properly understand and process categorical data.\\n\\nOne hot encoding is important in machine learning because it helps improve the performance and accuracy of the algorithms. By converting categorical variables into numerical form, the algorithms can better understand the relationships between different categories and make more accurate predictions.\\n\\nSteps Involved in One Hot Encoding\\n\\nThe steps involved in one hot encoding are as follows:\\n1. Identify the categorical variables that need to be encoded.\\n2. Create a binary matrix where each category is represented as a binary vector.\\n3. Replace the categorical variables with the binary matrix in the dataset.\\n\\nExample of One Hot Encoding in Action\\n\\nLet\\'s say we have a dataset with a categorical variable \"color\" with three categories: red, green, and blue. One hot encoding this variable would result in a binary matrix where each category is represented as follows:\\n- Red: [1, 0, 0]\\n- Green: [0, 1, 0]\\n- Blue: [0, 0, 1]\\n\\nAdvantages and Disadvantages of One Hot Encoding\\n\\nAdvantages:\\n- Preserves the information in the categorical variables.\\n- Improves the performance of machine learning algorithms.\\n- Easy to implement and understand.\\n\\nDisadvantages:\\n- Increases the dimensionality of the dataset.\\n- Can lead to the \"curse of dimensionality\" in some cases.\\n\\nConclusion and Final Thoughts on the Importance of One Hot Encoding in Data Preprocessing\\n\\nIn conclusion, one hot encoding is a crucial technique in data preprocessing for machine learning. By converting categorical variables into numerical form, it helps improve the performance and accuracy of machine learning algorithms. While it has some drawbacks, the advantages of one hot encoding far outweigh the disadvantages, making it an essential step in the data preprocessing pipeline.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "525e453e-c8c3-49a2-a314-b73d1c0c60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Introduction to one hot encoding\n",
      "- Explanation of what one hot encoding is and why it is used in machine learning\n",
      "- Steps involved in one hot encoding\n",
      "- Example of one hot encoding in action\n",
      "- Advantages and disadvantages of one hot encoding\n",
      "- Conclusion and final thoughts on the importance of one hot encoding in data preprocessing.\n"
     ]
    }
   ],
   "source": [
    "print(result['outline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b6f1318-3a5c-4007-95f1-c241fe1006eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to One Hot Encoding\n",
      "\n",
      "In the world of machine learning and data preprocessing, one hot encoding is a commonly used technique to convert categorical data into numerical data. This process is important because machine learning algorithms typically work with numerical data, and converting categorical data into numerical form allows these algorithms to better understand and process the data.\n",
      "\n",
      "Explanation of One Hot Encoding and its Importance in Machine Learning\n",
      "\n",
      "One hot encoding is a technique where categorical variables are converted into a binary matrix representation. Each category is represented as a binary vector where only one element is hot (1) and all others are cold (0). This allows machine learning algorithms to properly understand and process categorical data.\n",
      "\n",
      "One hot encoding is important in machine learning because it helps improve the performance and accuracy of the algorithms. By converting categorical variables into numerical form, the algorithms can better understand the relationships between different categories and make more accurate predictions.\n",
      "\n",
      "Steps Involved in One Hot Encoding\n",
      "\n",
      "The steps involved in one hot encoding are as follows:\n",
      "1. Identify the categorical variables that need to be encoded.\n",
      "2. Create a binary matrix where each category is represented as a binary vector.\n",
      "3. Replace the categorical variables with the binary matrix in the dataset.\n",
      "\n",
      "Example of One Hot Encoding in Action\n",
      "\n",
      "Let's say we have a dataset with a categorical variable \"color\" with three categories: red, green, and blue. One hot encoding this variable would result in a binary matrix where each category is represented as follows:\n",
      "- Red: [1, 0, 0]\n",
      "- Green: [0, 1, 0]\n",
      "- Blue: [0, 0, 1]\n",
      "\n",
      "Advantages and Disadvantages of One Hot Encoding\n",
      "\n",
      "Advantages:\n",
      "- Preserves the information in the categorical variables.\n",
      "- Improves the performance of machine learning algorithms.\n",
      "- Easy to implement and understand.\n",
      "\n",
      "Disadvantages:\n",
      "- Increases the dimensionality of the dataset.\n",
      "- Can lead to the \"curse of dimensionality\" in some cases.\n",
      "\n",
      "Conclusion and Final Thoughts on the Importance of One Hot Encoding in Data Preprocessing\n",
      "\n",
      "In conclusion, one hot encoding is a crucial technique in data preprocessing for machine learning. By converting categorical variables into numerical form, it helps improve the performance and accuracy of machine learning algorithms. While it has some drawbacks, the advantages of one hot encoding far outweigh the disadvantages, making it an essential step in the data preprocessing pipeline.\n"
     ]
    }
   ],
   "source": [
    "print(result['blog'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
