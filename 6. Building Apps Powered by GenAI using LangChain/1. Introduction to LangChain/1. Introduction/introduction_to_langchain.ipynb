{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc67735f-9fad-4a8f-bdd5-000e2e8bc79d",
   "metadata": {},
   "source": [
    "# **Introduction to LangChain**\n",
    "\n",
    "**Build Applications That Can Reason**\n",
    "\n",
    "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
    "\n",
    "### **Architecture**\n",
    "LangChain is a framework that consists of a number of packages.\n",
    "\n",
    "<img src=\"images/langchain_stack_updated.png\">\n",
    "\n",
    "**langchain-core**  \n",
    "This package contains base abstractions for different components and ways to compose them together. The interfaces for core components like **chat models**, **vector stores**, **tools** and more are defined here. No third-party integrations are defined here. The dependencies are very lightweight.\n",
    "\n",
    "**langchain**  \n",
    "The main langchain package contains chains and retrieval strategies that make up an application's cognitive architecture. These are NOT third-party integrations. All chains, agents, and retrieval strategies here are NOT specific to any one integration, but rather generic across all integrations.\n",
    "\n",
    "**Integration packages**  \n",
    "Popular integrations have their own packages (e.g. langchain-openai, langchain-anthropic, etc) so that they can be properly versioned and appropriately lightweight.\n",
    "\n",
    "**langchain-community**  \n",
    "This package contains third-party integrations that are maintained by the LangChain community. Key integration packages are separated out (see above). This contains integrations for various components (chat models, vector stores, tools, etc). All dependencies in this package are optional to keep the package as lightweight as possible.\n",
    "\n",
    "**langgraph**  \n",
    "langgraph is an extension of langchain aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\n",
    "\n",
    "LangGraph exposes high level interfaces for creating common types of agents, as well as a low-level API for composing custom flows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52685f3-d9f4-44b8-8e6a-364dd6c4c7fa",
   "metadata": {},
   "source": [
    "## **Chains - Prompt Template + Model + Output Parser**\n",
    "\n",
    "**Prompt Template**  \n",
    "- Prompt Templates are used to convert raw user input to a better input to the LLM. Templates allow us to easily configure and modify our input prompts to LLM calls.\n",
    "\n",
    "**Model**  \n",
    "- LLMs handle various language operations such as translation, summarization, question answering, and content creation.\n",
    "\n",
    "**Output Parser**  \n",
    "- It's often much more convenient to work with strings. We can add a simple output parser to convert the chat message to a string.\n",
    "\n",
    "**Chains**  \n",
    "- The `|` symbol chains together the different components feeds the output from one component as input into the next component.\n",
    "\n",
    "\n",
    "<img src=\"images/langchain_LCEL.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b6f7c0-1249-4832-be76-2c218489f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install langchain-openai\n",
    "\n",
    "# ! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df46bff6-1ec5-40b3-8c52-29f7d0862f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f6bed-567d-45a5-9381-e1b194caab5d",
   "metadata": {},
   "source": [
    "### **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4fb816-ea03-415d-b184-8262c5a494a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Feature engineering is the process of using domain knowledge to select, modify, or create new features (variables or attributes) from raw data to improve the performance of machine learning models. It is a crucial step in the machine learning workflow, as the quality and relevance of features can significantly influence the accuracy and effectiveness of a model.\\n\\nHere are some key aspects of feature engineering:\\n\\n1. **Feature Selection**: Identifying and selecting the most relevant features from the dataset. This can involve removing redundant or irrelevant features that do not contribute useful information for the model.\\n\\n2. **Feature Creation**: Generating new features from existing ones to provide more information to the model. This can include mathematical transformations, aggregating data points, or creating interaction terms between features.\\n\\n3. **Encoding**: Converting categorical variables into numerical formats that can be understood by machine learning algorithms. Common techniques include one-hot encoding, label encoding, and ordinal encoding.\\n\\n4. **Normalization/Standardization**: Scaling features to ensure they are on a similar scale, which can improve convergence during training and prevent models from being biased toward certain features.\\n\\n5. **Handling Missing Values**: Dealing with missing data appropriately, such as filling in gaps with mean/median values, using modeling techniques, or removing samples with missing values.\\n\\n6. **Outlier Detection/Treatment**: Identifying and handling outliers in the data, which can skew results and affect model performance.\\n\\n7. **Time-Series Features**: For time-dependent data, creating features that capture temporal patterns, trends, and seasonality can be essential.\\n\\n8. **Dimensionality Reduction**: Techniques such as Principal Component Analysis (PCA) can be used to reduce the number of features while retaining the most important information, which helps in simplifying models and reducing overfitting.\\n\\nEffective feature engineering often requires a combination of creativity and statistical analysis, and it is often an iterative process where features are continuously refined based on model performance. Well-engineered features can significantly improve model accuracy and interpretability, making feature engineering a critical aspect of the data science pipeline.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 419, 'prompt_tokens': 12, 'total_tokens': 431, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None} id='run-55ad2fab-8151-4907-a88a-4fcc542ac498-0' usage_metadata={'input_tokens': 12, 'output_tokens': 419, 'total_tokens': 431, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Creating a Prompt\n",
    "prompt = \"What is Feature Engineering?\"\n",
    "\n",
    "# Printing the output of model\n",
    "print(chat_model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6bafa1-110f-476f-88c1-03d6a77ed4c8",
   "metadata": {},
   "source": [
    "### **Prompts**\n",
    "\n",
    "Input to a model can be a **string** or **chat messages**.\n",
    "\n",
    "Prompt Template - Prompt templates are used to convert raw user input to a better input to the LLM or ChatModels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c510cec-a921-458a-a0ad-80fa09ccb8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI Tutor with expertise in Data Science and Artificial Intelligence. \"),\n",
    "    (\"human\", \"What is {topic}?\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5def41-723e-4b44-bf8e-378bcc647445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd03071-2c3f-4f0b-8190-96ee8aebc4b0",
   "metadata": {},
   "source": [
    "### **Chains**\n",
    "\n",
    "**The `|` symbol chains together the different components feeds the output from one component as input into the next component.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596048ab-59d5-4471-b41d-73802c503074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) and computational linguistics that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable computers to understand, interpret, generate, and respond to human language in a way that is both meaningful and useful.\\n\\nNLP encompasses a variety of tasks and applications, including but not limited to:\\n\\n1. **Text Analysis**: Analyzing and extracting information from text data, such as sentiment analysis, topic modeling, and named entity recognition.\\n\\n2. **Machine Translation**: Automatically translating text from one language to another (e.g., Google Translate).\\n\\n3. **Speech Recognition**: Converting spoken language into text (e.g., virtual assistants like Siri or Alexa).\\n\\n4. **Text Generation**: Producing coherent and contextually relevant text based on a prompt (e.g., chatbots, content generation).\\n\\n5. **Question Answering**: Developing systems that can answer questions posed in natural language, such as search engines or virtual assistants.\\n\\n6. **Information Retrieval**: Searching and retrieving relevant documents or data based on user queries.\\n\\n7. **Sentiment Analysis**: Determining the sentiment or emotional tone behind a series of words, often used in social media monitoring and customer feedback.\\n\\nNLP combines techniques from linguistics, computer science, and statistics to process and analyze large amounts of natural language data. It often involves the use of machine learning algorithms, particularly deep learning, to improve the understanding and generation of natural language.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 31, 'total_tokens': 342, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7fcd609668', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb6027f4-1488-4f5f-93b7-3fb9694566af-0', usage_metadata={'input_tokens': 31, 'output_tokens': 311, 'total_tokens': 342, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | chat_model\n",
    "\n",
    "raw_input = {'topic': \"NLP\"}\n",
    "\n",
    "chain.invoke(raw_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45960a9e-4e0a-4633-8e4f-eec1ded1b472",
   "metadata": {},
   "source": [
    "### **Output Parser**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c901e71-3aac-4fb0-870a-e21a1143a1d3",
   "metadata": {},
   "source": [
    "**The output of a ChatModel (and therefore, of this chain) is a AI Message. However, it's often much more convenient to work with strings. Let's add a simple output parser to convert the chat message to a string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1648a0-d87d-4f43-8fbc-47a185e60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Parsing\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82762c01-e6e0-4a1e-b070-1f051fb96704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning, which itself is a branch of artificial intelligence (AI). It involves the use of neural networks with many layers (hence the term \"deep\") to model and understand complex patterns in data. Here are some key points to understand about deep learning:\\n\\n1. **Neural Networks**: At its core, deep learning utilizes artificial neural networks, which are computational models inspired by the way biological neural networks in the human brain work. A typical neural network consists of an input layer, multiple hidden layers, and an output layer.\\n\\n2. **Layers**: The \"depth\" in deep learning comes from having multiple hidden layers between the input and output layers. Each layer consists of nodes (or neurons) that apply transformations to the input data and pass the resulting output to the next layer.\\n\\n3. **Feature Learning**: One of the strengths of deep learning is its ability to automatically learn features from raw data. This contrasts with traditional machine learning techniques, which often require manual feature engineering. For example, in image recognition tasks, deeper layers of a neural network can automatically learn to detect edges, shapes, and eventually more complex features like objects.\\n\\n4. **Big Data and Computational Power**: Deep learning thrives on large datasets and requires significant computational power, often utilizing GPUs (Graphics Processing Units) to accelerate the training process. The availability of big data and advances in hardware have contributed to the rise of deep learning.\\n\\n5. **Applications**: Deep learning has been successfully applied in various fields, including:\\n   - Computer vision (e.g., image classification, object detection)\\n   - Natural language processing (e.g., language translation, sentiment analysis)\\n   - Speech recognition\\n   - Game playing (e.g., AlphaGo)\\n   - Healthcare (e.g., disease diagnosis from medical images)\\n\\n6. **Popular Frameworks**: There are several popular deep learning frameworks, such as TensorFlow, PyTorch, Keras, and Caffe, which provide tools and libraries to build and train neural networks efficiently.\\n\\nOverall, deep learning has revolutionized many areas of AI by enabling models to achieve state-of-the-art performance on various tasks, making it a crucial area of study and application in data science and artificial intelligence.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modifying the chain: Adding output_parser\n",
    "chain = prompt_template | chat_model | output_parser\n",
    "\n",
    "raw_input = {\"topic\": \"deep learning\"}\n",
    "\n",
    "chain.invoke(raw_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930375ff-d9f7-4cf0-b4da-6fb16b39db7e",
   "metadata": {},
   "source": [
    "## **Example: Create an AI Tutor App that uses Prompts and Chat internally to give Python Implementation tutorial for Data Science topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a471dd0b-fb92-47cf-b09c-8266405a66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28998a35-5ebe-4900-a5f2-d360271756d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic_name'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nYou are a friendly AI Tutor with expertise in Data Science and AI who tells step by step Python Implementation for topics asked by user.\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic_name'], input_types={}, partial_variables={}, template='Tell me a python implementation for {topic_name}.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Constructing System Prompt\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are a friendly AI Tutor with expertise in Data Science and AI who tells step by step Python Implementation for topics asked by user.\n",
    "\"\"\")\n",
    "\n",
    "# Constructing Human Prompt\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"Tell me a python implementation for {topic_name}.\")\n",
    "\n",
    "# Compiling Chat Prompt\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6c48a5-b181-40b7-a8d0-f180b0a8bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8944772-4e6a-4fb5-a44a-2ebd29564846",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e52abfe-78d9-4a2a-a83b-c00fb93a91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a step-by-step Python implementation for Logistic Regression using the popular library `scikit-learn`:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import datasets\n",
      "from sklearn.metrics import accuracy_score\n",
      "```\n",
      "\n",
      "2. Load a sample dataset (for demonstration purposes, we will use the Iris dataset):\n",
      "```python\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "```\n",
      "\n",
      "3. Split the dataset into training and testing sets:\n",
      "```python\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "```\n",
      "\n",
      "4. Initialize the Logistic Regression model and fit it to the training data:\n",
      "```python\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "5. Make predictions on the test set:\n",
      "```python\n",
      "predictions = model.predict(X_test)\n",
      "```\n",
      "\n",
      "6. Evaluate the model performance by calculating the accuracy:\n",
      "```python\n",
      "accuracy = accuracy_score(y_test, predictions)\n",
      "print(f'Accuracy: {accuracy}')\n",
      "```\n",
      "\n",
      "This is a basic implementation of Logistic Regression using scikit-learn in Python. You can further tune the model by adjusting hyperparameters and preprocessing the data as needed.\n"
     ]
    }
   ],
   "source": [
    "raw_input = {\"topic_name\": \"Logistic Regression\"}\n",
    "\n",
    "output = chain.invoke(raw_input)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
