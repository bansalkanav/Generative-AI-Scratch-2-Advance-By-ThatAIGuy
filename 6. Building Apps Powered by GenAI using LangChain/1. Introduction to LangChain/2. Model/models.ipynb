{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23aea24-ce81-4540-8b2e-bf4e09fd6a67",
   "metadata": {},
   "source": [
    "# **Models** \n",
    "**(LLM and ChatModel)**\n",
    "\n",
    "- A model can be a **LLM** or a **ChatModel**.\n",
    "- LLMs handle various language operations such as translation, summarization, question answering, and content creation. **[Click Here](https://python.langchain.com/docs/integrations/llms/)** to check the complete list of LLMs which can be used with LangChain.\n",
    "- Chat Models are customized for conversational usage. **[Click Here](https://python.langchain.com/docs/integrations/chat/)** to check the complete list of LLMs which can be used with LangChain.\n",
    "- The output of a ChatModel (and therefore, of this chain) is a message.\n",
    "\n",
    "| Module | LLM | Chat Model |\n",
    "| :---: | :---: | :---: |\n",
    "| langchain_openai | OpenAI(api_key=key, model=`gpt-3.5-turbo-instruct`) | ChatOpenAI(api_key=key, model=`gpt-3.5-turbo`) |\n",
    "| langchain_google_genai | GoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) | ChatGoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) |\n",
    "| langchain_cohere | Cohere(api_key=key, model=`command`) | ChatCohere(api_key=key, model=`command`) |\n",
    "| langchain_anthropic | Anthropic(api_key=key, model=`claude-2.1`) | ChatAnthropic(api_key=key, model=`claude-3-opus-20240229`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bfea3-54f1-40f4-a08e-5e951df2ddf8",
   "metadata": {},
   "source": [
    "## **OpenAI - LLM and Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb318b67-fd03-4aab-ac8a-fe15c0231d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4402b36a-ced8-4157-a393-32f1a56f0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbc9226-091d-4c73-81a4-70e4e873112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanavbansal/Developer/.env_jupyter/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are a total of 28 states and 8 union territories in India, as of 2021.\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI LLM Model\n",
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a LLM model\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-instruct\", temperature=1)\n",
    "\n",
    "# Create a prompt\n",
    "prompt = \"How many states are there in India?\"\n",
    "\n",
    "# Pass the prompt to llm\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0745ecff-bf27-4e51-8562-1b68c3cc3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why did the data scientist bring a ladder to work?\\nBecause they heard the job required high-level analysis!' response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 15, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-23519b8b-c730-405d-bbed-aa8346b9a871-0' usage_metadata={'input_tokens': 15, 'output_tokens': 21, 'total_tokens': 36}\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "prompt = \"Tell me a short joke about Data Science\"\n",
    "\n",
    "print(chat_model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f2a7cc-9776-4952-9a68-572b5ff5dc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that allow computers to learn and improve from experience without being explicitly programmed. By using these algorithms and models, computers can analyze and interpret complex data, make predictions, and identify patterns or trends in data without human intervention. Machine learning can be applied to a wide range of tasks, such as image recognition, natural language processing, and autonomous driving.', response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 12, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-015b5da5-aaea-45a7-8d75-de05d95c989b-0', usage_metadata={'input_tokens': 12, 'output_tokens': 85, 'total_tokens': 97})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "prompt = \"What is Machine Learning?\"\n",
    "\n",
    "chain = model\n",
    "\n",
    "chain.invoke(prompt)\n",
    "\n",
    "# Observe that the output is a AI Message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81099d-8426-4f8e-8e9d-0cccd4915da3",
   "metadata": {},
   "source": [
    "## **Google GenAI - LLM and Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1698394c-12ae-4f5a-bf2f-f731f10a61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e380313c-365e-4a48-b96b-9828f6ae9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.gemini.txt')\n",
    "\n",
    "GOOGLE_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cad030-0dbf-4040-88bb-fcaf125a9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722949526.498150 2509327 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "# Import Google LLM Model\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a LLM model\n",
    "llm = GoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.5-flash\", temperature=1)\n",
    "\n",
    "# Create a prompt\n",
    "prompt = \"How many states are there in India?\"\n",
    "\n",
    "# Pass the prompt to llm\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079087d1-4adc-437a-bd8e-899e8a255294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Google ChatModel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.5-flash\", temperature=1)\n",
    "\n",
    "prompt = \"Tell me a short joke about Data Science\"\n",
    "\n",
    "print(chat_model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2dee74-1dac-47de-9f6d-6472435e4b5a",
   "metadata": {},
   "source": [
    "## **HuggingFace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f53c92e-c423-478d-8a4c-befa1dd93c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c5c234e-8502-4b20-af67-434d0d01057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"What should I study to become a data scientist?\\n\\nData scientist is not a field like programming or statistical computing. Instead, it consists of solving problems in real time in computer languages where the right question is being asked and then solving the problem using the help of mathematical constructs like R. Data scientists might be teaching students a particular data science problem, such as how to represent data in a data set, or a particular data set in a way that the student's intuition will recognize rather than being forced in a computer language.\\n\\nThe problem of using R in a data science lesson focuses primarily on problem solving concepts. However, we can create the problem of data science in a data science classroom. For example, we might teach a student the problem of getting to a new data store on the go. In which case we might teach the students that we want to look for a dataset that will allow us to store their results in a digital format and display them through an algorithm.\\n\\nMany computer science courses teach a little about the use of R data science to learn how to write programs like this one. Students will probably go through our introductory data science course and will find that this class focuses mostly on doing the job of writing code and writing complex programs with R. The class is also devoted to creating and maintaining R applications that can be used to automate basic tasks we do in data science. A small number of programming programs can be found in the course, as well as some of our courses and tutorials.\\n\\nFor more on our courses and tutorials, visit our Coursera Learning page.\\n\\nDo you have any questions? Please comment below.\\n\\nSource: http://gop.net/\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512\n",
    ")\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "hf.invoke(\"What should I study to become a data scientist?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac923cd0-f293-4916-9f69-8164931e542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254dbe6f25fd4fd29d9a977e3a1653b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login() # You will be prompted for your HF key, which will then be saved locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc043b69-f470-48d0-aee8-4bb72f4abd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58703752-fd54-4562-bb1b-4df254caeb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Foundations:\\nA. Basic math and statistics: Familiarize yourself with fundamental concepts such as algebra, calculus, probability, and statistics.\\n\\nB. Programming: Learn a programming language that is commonly used in data science, such as Python, R, or Julia. Start with Python, as it has a vast array of libraries and community support.\\n\\n2. Data manipulation and analysis:\\nA. Data wrangling: Learn how to import', response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=100, prompt_tokens=13, total_tokens=113), 'model': '', 'finish_reason': 'length'}, id='run-269eb770-54e7-4741-bc89-e3a49ca86754-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"What is a curriculum to learn datascience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b7ab2-13f6-4e44-bdc7-e0efbc3b0974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
