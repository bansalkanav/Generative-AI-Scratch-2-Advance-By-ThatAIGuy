{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23aea24-ce81-4540-8b2e-bf4e09fd6a67",
   "metadata": {},
   "source": [
    "# **Models** \n",
    "**(LLM and ChatModel)**\n",
    "\n",
    "- A model can be a **LLM** or a **ChatModel**.\n",
    "- LLMs handle various language operations such as translation, summarization, question answering, and content creation. **[Click Here](https://python.langchain.com/docs/integrations/llms/)** to check the complete list of LLMs which can be used with LangChain.\n",
    "- Chat Models are customized for conversational usage. **[Click Here](https://python.langchain.com/docs/integrations/chat/)** to check the complete list of LLMs which can be used with LangChain.\n",
    "- The output of a ChatModel (and therefore, of this chain) is a message.\n",
    "\n",
    "| Module | LLM | Chat Model |\n",
    "| :---: | :---: | :---: |\n",
    "| langchain_openai | OpenAI(api_key=key, model=`gpt-3.5-turbo-instruct`) | ChatOpenAI(api_key=key, model=`gpt-3.5-turbo`) |\n",
    "| langchain_google_genai | GoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) | ChatGoogleGenerativeAI(api_key=key, model=`gemini-1.5-pro-latest`) |\n",
    "| langchain_cohere | Cohere(api_key=key, model=`command`) | ChatCohere(api_key=key, model=`command`) |\n",
    "| langchain_anthropic | Anthropic(api_key=key, model=`claude-2.1`) | ChatAnthropic(api_key=key, model=`claude-3-opus-20240229`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bfea3-54f1-40f4-a08e-5e951df2ddf8",
   "metadata": {},
   "source": [
    "## **OpenAI - LLM and Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb318b67-fd03-4aab-ac8a-fe15c0231d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4402b36a-ced8-4157-a393-32f1a56f0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbc9226-091d-4c73-81a4-70e4e873112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "India has 29 states and 7 union territories, making a total of 36 administrative divisions.\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI LLM Model\n",
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a LLM model\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-instruct\", temperature=1)\n",
    "\n",
    "# Create a prompt\n",
    "prompt = \"How many states are there in India?\"\n",
    "\n",
    "# Pass the prompt to llm\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0745ecff-bf27-4e51-8562-1b68c3cc3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why was the data scientist always calm? Because they had good \"data-minimization\" techniques!' response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 15, 'total_tokens': 34}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# Import OpenAI ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "prompt = \"Tell me a short joke about Data Science\"\n",
    "\n",
    "print(chat_model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f2a7cc-9776-4952-9a68-572b5ff5dc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that involves developing algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data, without being explicitly programmed to do so. Machine learning algorithms use patterns in data to make informed decisions and improve their performance over time. This technology is used in a wide range of applications, including image and speech recognition, medical diagnosis, recommendation systems, and predictive analytics.', response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 12, 'total_tokens': 95}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "prompt = \"What is Machine Learning?\"\n",
    "\n",
    "chain = model\n",
    "\n",
    "chain.invoke(prompt)\n",
    "\n",
    "# Observe that the output is a AI Message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81099d-8426-4f8e-8e9d-0cccd4915da3",
   "metadata": {},
   "source": [
    "## **Google GenAI - LLM and Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1698394c-12ae-4f5a-bf2f-f731f10a61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e380313c-365e-4a48-b96b-9828f6ae9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.gemini.txt')\n",
    "\n",
    "GOOGLE_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cad030-0dbf-4040-88bb-fcaf125a9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 2023, India has 28 states. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Google LLM Model\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a LLM model\n",
    "llm = GoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.5-pro-latest\", temperature=1)\n",
    "\n",
    "# Create a prompt\n",
    "prompt = \"How many states are there in India?\"\n",
    "\n",
    "# Pass the prompt to llm\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "079087d1-4adc-437a-bd8e-899e8a255294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why did the data scientist get lost on their way to work? \\n\\nThey took a wrong turn on the decision tree! \\n' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}\n"
     ]
    }
   ],
   "source": [
    "# Import Google ChatModel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.5-pro-latest\", temperature=1)\n",
    "\n",
    "prompt = \"Tell me a short joke about Data Science\"\n",
    "\n",
    "print(chat_model.invoke(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
